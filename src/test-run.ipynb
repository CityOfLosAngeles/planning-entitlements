{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# obs in m2: 314716\n",
      "# obs in m2 after dropping AINs not in our crosswalk: 283487\n",
      "# obs when we join cases and geo_info: 557848\n",
      "# obs where PROP_ID was NaN: 5781\n",
      "% where PROP_ID was NaN: 0.01036303796016119\n",
      "# unique CASE_IDs in correct_joins: 49163\n",
      "# unique CASE_IDs in incorrect_joins: 5781\n",
      "# unique PARENT_CASEs in correct_joins: 48162\n",
      "# unique PARENT_CASEs in incorrect_joins: 5471\n",
      "# unique PARENT_CASEs that were correctly joined, but also appear in incorrect_joins\n",
      "1709\n",
      "# obs in incorrect_joins before m:m merge: 5781\n",
      "# unqiue PARENT_CASEs in incorrect_joins before m:m merge: 5471\n",
      "# obs in incorrect_joins after m:m merge: 19812\n",
      "# unqiue PARENT_CASEs in incorrect_joins after m:m merge: 5471\n",
      "# obs in incorrect_joins once we add in AIN: 19812\n",
      "# unqiue PARENT_CASEs once we add in AIN: 5471\n",
      "# unique lost PARENT_CASEs: 3400\n",
      "Double check, try to find some in geo_info: 0\n",
      "# obs in incorrect_joins that were fixed: 16310\n",
      "# unique PARENT_CASEs in incorrect_joins that were fixed: 2071\n",
      "# unique PARENT_CASEs in incorrect_joins before all this: 5471\n",
      "# obs in m3: 349897\n",
      "# obs in m1: 557848\n",
      "# unique CASE_IDs in m3: 49844\n",
      "# unique CASE_IDs in m1: 54944\n",
      "# unique PARENT_CASEs in m3: 47046\n",
      "# unique PARENT_CASEs in m1: 51924\n",
      "# obs in m4: 349897\n",
      "# unique CASE_ID in m4: 49844\n",
      "# unique PARENT_CASEs in m4: 47046\n",
      "# obs in m5: 349897\n",
      "# unique CASE_ID in m5: 49844\n",
      "# unique PARENT_CASEs in m5: 47046\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Make a master PCTS file.\n",
    "\"\"\" \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import intake\n",
    "\n",
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "bucket_name = 'city-planning-entitlements'\n",
    "\n",
    "# Import data\n",
    "cases = pd.read_parquet(f's3://{bucket_name}/data/raw/tCASE.parquet')\n",
    "app = pd.read_parquet(f's3://{bucket_name}/data/raw/tAPLC.parquet')\n",
    "geo_info = pd.read_parquet(f's3://{bucket_name}/data/raw/tPROP_GEO_INFO.parquet')\n",
    "la_prop = pd.read_parquet(f's3://{bucket_name}/data/raw/tLA_PROP.parquet')\n",
    "\n",
    "crosswalk_parcels_tracts = (catalog.crosswalk_parcels_tracts.read()\n",
    "    [[\"uuid\", \"AIN\"]]\n",
    ")\n",
    "\n",
    "# Define functions to create master PCTS data\n",
    "def merge_pcts(cases, geo_info, la_prop, app, crosswalk_parcels_tracts):\n",
    "    # Subset dataframes before merging\n",
    "    keep_col = ['CASE_ID', 'APLC_ID', 'CASE_NBR', \n",
    "                    'CASE_SEQ_NBR', 'CASE_YR_NBR', 'CASE_ACTION_ID', \n",
    "                    'CASE_FILE_RCV_DT', 'CASE_FILE_DATE', 'PARNT_CASE_ID']\n",
    "\n",
    "    cases1 = (cases.assign(\n",
    "        # Grab the year-month from received date\n",
    "        CASE_FILE_DATE = pd.to_datetime(cases['CASE_FILE_RCV_DT']).dt.to_period('M'),\n",
    "    )[keep_col])\n",
    "    \n",
    "    app1 = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "    geo_info1 = geo_info[['CASE_ID', 'PROP_ID']]\n",
    "    la_prop1 = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]\n",
    "    \n",
    "    # Identify parent cases\n",
    "    cases1['parent_is_null'] = cases1.PARNT_CASE_ID.isna()\n",
    "    cases1['PARENT_CASE'] = cases1.apply(lambda row: row.CASE_ID if row.parent_is_null == True \n",
    "                                             else row.PARNT_CASE_ID, axis = 1)\n",
    "    \n",
    "    # Keep cases from 2010 onward\n",
    "    cases2 = cases1[cases1.CASE_FILE_DATE.dt.year >= 2010]\n",
    "    \n",
    "    final = join_tables(cases2, geo_info1, la_prop1, app1, crosswalk_parcels_tracts)\n",
    "  \n",
    "    return final\n",
    "\n",
    "def join_tables(cases2, geo_info1, la_prop1, app1, crosswalk_parcels_tracts):\n",
    "    # Merge with geo_info, la_prop, parcels to ID the parcels that have entitlements\n",
    "    # Inner join would lose appeals cases, switch to left join instead.\n",
    "    # (1) Merge cases and geo_info to get PROP_ID\n",
    "    m1 = pd.merge(cases2, geo_info1, on = 'CASE_ID', how = 'left', validate = '1:m')\n",
    "\n",
    "    correct_joins = m1[m1.PROP_ID.notna()]\n",
    "    incorrect_joins = m1[m1.PROP_ID.isna()]\n",
    "\n",
    "    # (2) Merge geo_info and la_prop to link PROP_IDs and AINs\n",
    "    # Drop PROP_IDs that wouldn't have gotten linked to any AIN anyway\n",
    "    m2 = (pd.merge(geo_info1[[\"PROP_ID\"]].drop_duplicates(), \n",
    "               la_prop1, \n",
    "               on = \"PROP_ID\", how = \"left\", validate = \"1:m\")\n",
    "      .rename(columns = {\"ASSR_PRCL_NBR\": \"AIN\"})\n",
    "     )\n",
    "\n",
    "    print(f\"# obs in m2: {len(m2)}\")\n",
    "    m2 = m2[m2.AIN.isin(crosswalk_parcels_tracts.AIN)]\n",
    "    print(f\"# obs in m2 after dropping AINs not in our crosswalk: {len(m2)}\")\n",
    "\n",
    "    # (3a) Fix incorrect obs with a m:m merge so they can get PROP_ID using PARENT_CASE\n",
    "    incorrect_joins_with_propid = pd.merge(\n",
    "                            incorrect_joins.drop(columns = [\"PROP_ID\"]), \n",
    "                            geo_info1.rename(columns = {\"CASE_ID\": \"PARENT_CASE\"}), \n",
    "                            on = \"PARENT_CASE\", how = \"left\", validate = \"m:m\"\n",
    "    )\n",
    "\n",
    "    incorrect_joins_with_ain = pd.merge(\n",
    "        incorrect_joins_with_propid, m2,\n",
    "        on = \"PROP_ID\", how = \"left\", validate = \"m:1\"\n",
    "    )\n",
    "    \n",
    "    # (3b) Get rid of obs where we can't link to PROP_ID and AIN\n",
    "    incorrect_joins_now_fixed = incorrect_joins_with_ain[incorrect_joins_with_ain.PROP_ID.notna()]\n",
    "    \n",
    "    # (4a) Merge in AIN info using PROP_ID for correct ones after m1\n",
    "    correct_joins_with_ain = pd.merge(correct_joins, m2, \n",
    "                            on = \"PROP_ID\", how = \"inner\", validate = \"m:1\")\n",
    "    \n",
    "    # (4b) Concatenate the 2 parts together\n",
    "    m3 = (pd.concat([\n",
    "            correct_joins_with_ain, \n",
    "            incorrect_joins_now_fixed\n",
    "        ], axis=0)\n",
    "        .sort_values([\"CASE_ID\", \"AIN\", \"PROP_ID\"])\n",
    "        .drop_duplicates(subset = [\"CASE_ID\", \"AIN\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # (5) Merge in app to get project description\n",
    "    m4 = pd.merge(m3, app1, on = \"APLC_ID\", how = \"left\", validate = \"m:1\")\n",
    "\n",
    "    m5 = (\n",
    "        m4.drop(columns = ['PROP_ID', 'parent_is_null'])\n",
    "        # Nothing dropped here, but just in case\n",
    "        .drop_duplicates()\n",
    "        .sort_values(['CASE_ID', 'AIN'])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print_statements(m1, correct_joins, incorrect_joins, \n",
    "                     incorrect_joins_with_propid, incorrect_joins_with_ain, \n",
    "                     geo_info1, incorrect_joins_now_fixed, \n",
    "                     m3, m4, m5)\n",
    "\n",
    "    return m5\n",
    "\n",
    "def print_statements(m1, correct_joins, incorrect_joins, \n",
    "                     incorrect_joins_with_propid, incorrect_joins_with_ain, \n",
    "                     geo_info1, incorrect_joins_now_fixed, \n",
    "                     m3, m4, m5):\n",
    "    print(f\"# obs when we join cases and geo_info: {len(m1)}\")\n",
    "    print(f\"# obs where PROP_ID was NaN: {len(incorrect_joins)}\")\n",
    "    print(f\"% where PROP_ID was NaN: {len(incorrect_joins) / len(m1)}\")\n",
    "\n",
    "    print(f\"# unique CASE_IDs in correct_joins: {correct_joins.CASE_ID.nunique()}\")\n",
    "    print(f\"# unique CASE_IDs in incorrect_joins: {incorrect_joins.CASE_ID.nunique()}\")\n",
    "\n",
    "    print(f\"# unique PARENT_CASEs in correct_joins: {correct_joins.PARENT_CASE.nunique()}\")\n",
    "    print(f\"# unique PARENT_CASEs in incorrect_joins: {incorrect_joins.PARENT_CASE.nunique()}\")\n",
    "   \n",
    "   # Of these incorrect joins, do they share parent cases with ones that were joined?\n",
    "    print(\"# unique PARENT_CASEs that were correctly joined, but also appear in incorrect_joins\")\n",
    "    print(f\"{incorrect_joins[incorrect_joins.PARENT_CASE.isin(correct_joins.PARENT_CASE)].PARENT_CASE.nunique()}\")\n",
    "\n",
    "    print(f\"# obs in incorrect_joins before m:m merge: {len(incorrect_joins)}\")\n",
    "    print(f\"# unqiue PARENT_CASEs in incorrect_joins before m:m merge: {incorrect_joins.PARENT_CASE.nunique()}\")\n",
    "    print(f\"# obs in incorrect_joins after m:m merge: {len(incorrect_joins_with_propid)}\")\n",
    "    print(f\"# unqiue PARENT_CASEs in incorrect_joins after m:m merge: {incorrect_joins_with_propid.PARENT_CASE.nunique()}\")\n",
    "\n",
    "    print(f\"# obs in incorrect_joins once we add in AIN: {len(incorrect_joins_with_ain)}\")\n",
    "    print(f\"# unqiue PARENT_CASEs once we add in AIN: {incorrect_joins_with_ain.PARENT_CASE.nunique()}\")\n",
    "    \n",
    "    lost_parents = (incorrect_joins_with_ain[incorrect_joins_with_ain.PROP_ID.isna()]\n",
    "                    [[\"PARENT_CASE\"]].drop_duplicates()\n",
    "                )\n",
    "\n",
    "    print(f\"# unique lost PARENT_CASEs: {len(lost_parents)}\")\n",
    "    print(f\"Double check, try to find some in geo_info: {len(geo_info1[geo_info1.CASE_ID.isin(lost_parents.PARENT_CASE)])}\")\n",
    "\n",
    "    print(f\"# obs in incorrect_joins that were fixed: {len(incorrect_joins_now_fixed)}\")\n",
    "    print(f\"# unique PARENT_CASEs in incorrect_joins that were fixed: {incorrect_joins_now_fixed.PARENT_CASE.nunique()}\")\n",
    "    print(f\"# unique PARENT_CASEs in incorrect_joins before all this: {incorrect_joins.PARENT_CASE.nunique()}\")\n",
    "    \n",
    "    print(f\"# obs in m3: {len(m3)}\")\n",
    "    print(f\"# obs in m1: {len(m1)}\")\n",
    "\n",
    "    print(f\"# unique CASE_IDs in m3: {m3.CASE_ID.nunique()}\")\n",
    "    print(f\"# unique CASE_IDs in m1: {m1.CASE_ID.nunique()}\")\n",
    "\n",
    "    print(f\"# unique PARENT_CASEs in m3: {m3.PARENT_CASE.nunique()}\")\n",
    "    print(f\"# unique PARENT_CASEs in m1: {m1.PARENT_CASE.nunique()}\")\n",
    "\n",
    "    print(f\"# obs in m4: {len(m4)}\")\n",
    "    print(f\"# unique CASE_ID in m4: {m4.CASE_ID.nunique()}\")\n",
    "    print(f\"# unique PARENT_CASEs in m4: {m4.PARENT_CASE.nunique()}\")\n",
    "\n",
    "    print(f\"# obs in m5: {len(m5)}\")\n",
    "    print(f\"# unique CASE_ID in m5: {m5.CASE_ID.nunique()}\")\n",
    "    print(f\"# unique PARENT_CASEs in m5: {m5.PARENT_CASE.nunique()}\")\n",
    "\n",
    "\n",
    "# Create master PCTS and parent cases df and export to S3\n",
    "df = merge_pcts(cases, geo_info, la_prop, app, crosswalk_parcels_tracts)\n",
    "#df.to_parquet(f's3://{bucket_name}/data/final/master_pcts.parquet')\n",
    "df.to_parquet('s3://city-planning-entitlements/test_new_master_pcts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
