{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New merges for master_pcts\n",
    "* Losing appeals cases because of an inner join\n",
    "* These appeals child cases aren't associated with an AIN, but we can grab it from parent case\n",
    "* But, merging using PARENT_CASE rather than CASE_ID means it's a m:m merge (gross!)\n",
    "* Figure out if we can expand the merges, switch the order, and create new master_pcts\n",
    "* Add print statements to check the length of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import intake\n",
    "\n",
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "bucket_name = 'city-planning-entitlements'\n",
    "\n",
    "# Import data\n",
    "cases = pd.read_parquet(f's3://{bucket_name}/data/raw/tCASE.parquet')\n",
    "app = pd.read_parquet(f's3://{bucket_name}/data/raw/tAPLC.parquet')\n",
    "geo_info = pd.read_parquet(f's3://{bucket_name}/data/raw/tPROP_GEO_INFO.parquet')\n",
    "la_prop = pd.read_parquet(f's3://{bucket_name}/data/raw/tLA_PROP.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframes before merging\n",
    "keep_col = ['CASE_ID', 'APLC_ID', 'CASE_NBR', \n",
    "                'CASE_SEQ_NBR', 'CASE_YR_NBR', 'CASE_ACTION_ID', \n",
    "                'CASE_FILE_RCV_DT', 'CASE_FILE_DATE', 'PARNT_CASE_ID']\n",
    "\n",
    "cases1 = (cases.assign(\n",
    "    # Grab the year-month from received date\n",
    "    CASE_FILE_DATE = pd.to_datetime(cases['CASE_FILE_RCV_DT']).dt.to_period('M'),\n",
    ")[keep_col])\n",
    "\n",
    "app1 = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "geo_info1 = geo_info[['CASE_ID', 'PROP_ID']].drop_duplicates()\n",
    "la_prop1 = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]\n",
    "\n",
    "# Identify parent cases\n",
    "cases1['parent_is_null'] = cases1.PARNT_CASE_ID.isna()\n",
    "cases1['PARENT_CASE'] = cases1.apply(lambda row: row.CASE_ID if row.parent_is_null == True \n",
    "                                         else row.PARNT_CASE_ID, axis = 1)\n",
    "\n",
    "# Keep cases from 2010 onward\n",
    "cases2 = cases1[cases1.CASE_FILE_DATE.dt.year >= 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First merge is between cases and geo_info\n",
    "We add on PROP_ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(cases2, geo_info1, on = 'CASE_ID', how = 'left', validate = '1:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_joins = m1[m1.PROP_ID.notna()]\n",
    "incorrect_joins = m1[m1.PROP_ID.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# obs when we join cases and geo_info: {len(m1)}\")\n",
    "print(f\"# obs where PROP_ID was NaN: {len(incorrect_joins)}\")\n",
    "print(f\"% where PROP_ID was NaN: {len(incorrect_joins) / len(m1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of these incorrect joins, do they share parent cases with ones that were joined?\n",
    "print(\"# unique parents that were correctly joined, but also appear in incorrect_joins\")\n",
    "print(f\"{incorrect_joins[incorrect_joins.PARENT_CASE.isin(correct_joins.PARENT_CASE)].PARENT_CASE.nunique()}\")\n",
    "print(f\"# unique parents in incorrect_joins: {incorrect_joins.PARENT_CASE.nunique()}\")\n",
    "\n",
    "# This shows a lot of parent cases won't get joined to a PROP_ID and AIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big rabbit hole that will never get rid of the m:m merge.\n",
    "(1) There are PARENT_CASES where some of their CASE_IDs have PROP_ID merged, and some CASE_IDs that did not correctly join with PROP_ID. These PARENT_IDs will have some obs in correctly_joined and some in incorrectly_joined. This will involve m:m merge.\n",
    "(2) There are also that fall completely within incorrectly_joined, and using PARENT_CASE, we can get PROP_IDs. This will involve m:m merge.\n",
    "(3) There are also PARENT_CASEs that are only in incorrectly_joined, but we cannot get PROP_ID for them at the end of all this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appear_in_correct = (incorrect_joins[incorrect_joins.PARENT_CASE.isin(correct_joins.PARENT_CASE)]\n",
    "                     [[\"PARENT_CASE\"]]\n",
    "                     .drop_duplicates()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_me = m1[m1.PARENT_CASE.isin(appear_in_correct.PARENT_CASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_me_crosswalk = fix_me[[\"PARENT_CASE\", \"PROP_ID\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(fix_me, fix_me_crosswalk, on = \"PARENT_CASE\", how = \"left\", validate = \"m:m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second merge is between geo_info and la_prop\n",
    "* To fix these incorrect joins, we would have to have allowed a m:m merge.\n",
    "* So, let's see if we can circumvent PROP_ID by mapping it to AIN directly.\n",
    "* But first, we force it to be a 1:m merge, and only keep unique PROP_IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a second merge for PROP_ID and AINs\n",
    "m2 = (pd.merge(geo_info1[[\"PROP_ID\"]].drop_duplicates(), \n",
    "               la_prop1, \n",
    "               on = \"PROP_ID\", how = \"left\", validate = \"1:m\")\n",
    "      .rename(columns = {\"ASSR_PRCL_NBR\": \"AIN\"})\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third merge is to create a CASE_ID to AIN crosswalk\n",
    "\n",
    "* Combine the results of the previous 2 merges. Use PROP_ID to join cases with la_prop.\n",
    "* But first, bring in our crosswalk_parcels_tracts to make sure we only keep parcels we have.\n",
    "* Then, combine case info with AIN and get rid of all the duplicates.\n",
    "* When we merge AIN info onto all our cases, we can then avoid using PROP_ID and the m:m merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk_parcels_tracts = (pd.read_parquet(\n",
    "    \"s3://city-planning-entitlements/data/crosswalk_parcels_tracts_lacity.parquet\")\n",
    "    [[\"uuid\", \"AIN\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ain_side = m2[m2.AIN.isin(crosswalk_parcels_tracts.AIN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ain_side.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_joins_with_propid = pd.merge(incorrect_joins.drop(columns = [\"PROP_ID\"]), \n",
    "                                       geo_info1.rename(columns = {\"CASE_ID\": \"PARENT_CASE\"}), \n",
    "                                       on = \"PARENT_CASE\", how = \"inner\", validate = \"m:m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_joins_with_ain = pd.merge(incorrect_joins_with_propid, ain_side,\n",
    "                                    on = \"PROP_ID\", how = \"inner\", validate = \"m:1\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_joins.PARENT_CASE.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_joins_with_ain.PARENT_CASE.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth merge is to add on project description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
