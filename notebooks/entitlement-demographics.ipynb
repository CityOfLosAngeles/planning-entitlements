{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the demographic characteristics of neighborhoods where entitlements are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "cat = intake.open_catalog(\"../catalogs/*.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCTS extract\n",
    "pcts = cat.pcts2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS data for income, race, commute, tenure\n",
    "census = pandas.read_parquet(\n",
    "    \"s3://city-planning-entitlements/data/final/census_cleaned.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census tracts\n",
    "tracts = cat.census_tracts.read()\n",
    "tracts = tracts.assign(\n",
    "    density=tracts.HD01_VD01.astype(int)/(tracts.Shape_STAr/5280./5280.),\n",
    "    population=tracts.HD01_VD01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_to_tract = pandas.read_parquet(\n",
    "    \"s3://city-planning-entitlements/data/crosswalk_parcels_tracts.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The requested entitlements are in the suffixes of the PCTS case number.\n",
    "# A given case can have an arbitrary number of entitlement suffixes, so\n",
    "# we need to parse it into its component parts.\n",
    "# We can use a regex for that:\n",
    "\n",
    "from utils import GENERAL_PCTS_RE\n",
    "cols = pcts.CASE_NBR.str.extract(GENERAL_PCTS_RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_suffixes = cols[3].str.strip(\"-\").str.split(\"-\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_counts = (all_suffixes\n",
    "    .apply(lambda col: col.value_counts(), axis=0)\n",
    "    .sum(axis=1)\n",
    "    .astype(int)\n",
    "    .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate each PCTS entitlement case with a census tract:\n",
    "pcts = pcts.merge(\n",
    "    parcel_to_tract[[\"GEOID\", \"AIN\"]],\n",
    "    how=\"left\",\n",
    "    on=\"AIN\",\n",
    ").merge(\n",
    "    tracts[[\"GEOID10\", \"population\", \"density\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"GEOID\",\n",
    "    right_on=\"GEOID10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts_suffixes = pandas.concat((pcts, all_suffixes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each case can have multiple suffixes. However, it is useful\n",
    "# to be able to refer to a single suffix column when performing\n",
    "# aggregations and computing statistics.\n",
    "# Here we melt the suffix columns into a single column.\n",
    "# This has the effect of creating multiple rows for cases\n",
    "# that have multiple entitlements being requested.\n",
    "\n",
    "pcts_suffixes = pcts_suffixes.melt(\n",
    "    id_vars=pcts.columns,\n",
    "    var_name=\"nothing\",\n",
    "    value_name=\"suffix\"\n",
    ").dropna(subset=[\"suffix\"]).drop(columns=[\"GEOID10\", \"nothing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first pass at analyzing entitlements is to count the number\n",
    "# of cases for each census tract, to see which kinds of entitlements\n",
    "# are being applied for in which types of census tract:\n",
    "entitlement = (pcts_suffixes\n",
    "    .groupby([\"GEOID\", \"suffix\", \"CASE_YR_NBR\"])\n",
    "    .size()\n",
    "    .to_frame(\"count\")\n",
    ").reset_index(level=1).reset_index(level=1).rename(columns={\"CASE_YR_NBR\": \"year\"})\n",
    "entitlement = entitlement.assign(\n",
    "    year=entitlement.year.astype(\"Int64\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We next calculate incomes on a census tract level.\n",
    "# We pivot the `new_var` column into wide format to get a column for each variable.\n",
    "income = census[(census.table == \"incomerange\") & (census.year == 2018)]\n",
    "income = income.pivot(index=\"GEOID\", columns=\"new_var\", values=\"num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the income data with the entitlements counts:\n",
    "joined = pandas.merge(\n",
    "    income,\n",
    "    entitlement,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'd like to calculate income percentiles from the reported ranges.\n",
    "# The following function takes a row from the pivoted ACS data,\n",
    "# and estimates a set of percentiles from the binned data:\n",
    "def income_percentiles(row, percentiles, prefix=\"total\"):\n",
    "    # Edges of the reported income bins, in thousands of dollars\n",
    "    bins = [0, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 75, 100, 125, 150, 200]\n",
    "    # Iterator over percentiles\n",
    "    p_it = iter(percentiles)\n",
    "    # Final values for percentiles\n",
    "    values = []\n",
    "    # Initialize current percentile and an accumulator variable\n",
    "    curr = next(p_it)\n",
    "    acc = 0\n",
    "    # The total count for the tract\n",
    "    total = row[f\"{prefix}_total\"]\n",
    "    if total <= 0:\n",
    "        return values\n",
    "    for i, b in enumerate(bins):\n",
    "        # Compute the label of the current bin\n",
    "        if i == 0:\n",
    "            label = f\"{prefix}_lt{bins[i+1]}\"\n",
    "        elif i == len(bins) - 1:\n",
    "            label = f\"{prefix}_gt{b}\"\n",
    "        else:\n",
    "            label = f\"{prefix}_r{b}to{bins[i+1]-1}\"\n",
    "        # Estimate the value for the current percentile\n",
    "        # if it falls within this bin\n",
    "        while (acc + row[label])/total > curr/100.0:\n",
    "            frac = (total*curr/100.0 - acc)/row[label]\n",
    "            lower = b\n",
    "            upper = bins[i+1] if i < (len(bins) - 1) else 300. \n",
    "            interp = (1.0 - frac) * lower + frac * upper\n",
    "            values.append(interp)\n",
    "            try:\n",
    "                curr = next(p_it)\n",
    "            except StopIteration:\n",
    "                return values\n",
    "        # Increment the accumulator\n",
    "        acc = acc + row[label]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the inter-quartile range for the income data:\n",
    "iqr = joined.apply(\n",
    "    lambda r: pandas.Series(income_percentiles(r, [25,50,75]), dtype=\"float64\"),\n",
    "    axis=1,\n",
    ").rename(columns={0: \"Q1\", 1: \"Q2\", 2: \"Q3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pandas.concat((joined, iqr), axis=1)[[\"Q1\", \"Q2\", \"Q3\", \"suffix\", \"year\", \"count\"]]\n",
    "# Bring in population density\n",
    "joined = joined.reset_index().merge(\n",
    "    tracts[[\"GEOID10\", \"density\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"GEOID\",\n",
    "    right_on=\"GEOID10\",\n",
    ").drop(columns=\"GEOID10\").set_index(\"GEOID\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot entitlement stats against median household income,\n",
    "# population density, and geography:\n",
    "def plot_entitlement(df, tracts, suffix, year=\"2017\"):\n",
    "    if year == \"all\":\n",
    "        to_plot = df[(df[\"count\"] > 0) & (df.year >= 2010) & (df.suffix == suffix)]\n",
    "        to_plot = to_plot.groupby(to_plot.index).agg({\n",
    "            \"count\": \"sum\",\n",
    "            \"Q2\": \"first\",\n",
    "            \"density\": \"first\"\n",
    "        })\n",
    "    else:\n",
    "        to_plot = df[(df[\"count\"] > 0) & (df.year == int(year)) & (df.suffix == suffix)]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=1)\n",
    "    ax1.set_xlabel(\"Median income\")\n",
    "    ax1.set_ylabel(\"Entitlement count per tract\")\n",
    "    ax1.scatter(to_plot.Q2, to_plot[\"count\"])\n",
    "\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0), colspan=1)\n",
    "    ax2.set_xlabel(\"Population density\")\n",
    "    ax2.set_ylabel(\"Entitlement count per tract\")\n",
    "    ax2.scatter(to_plot.density, to_plot[\"count\"])\n",
    "\n",
    "    ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "    ax3.axis(\"off\")\n",
    "    tracts.merge(\n",
    "        to_plot,\n",
    "        left_on=\"GEOID10\",\n",
    "        right_index=True,\n",
    "        how=\"left\"\n",
    "    ).fillna(\n",
    "        {\"count\": 0}\n",
    "    ).plot(\n",
    "        ax=ax3,\n",
    "        column=\"count\",\n",
    "        cmap=\"magma\",\n",
    "    )\n",
    "    plt.close() # Prevent double plotting\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f8049f12e74618847b7ef3dc5a5c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Year', options=(('All (from 2010 - present)', 'all'), ('2010', '2010'), ('2011', '2011')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c0d453b0c14fecaf858590e8768a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Suffix', options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2fead83bb642a0b8dc4b557470f2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "\n",
    "years = [(\"All (from 2010 - present)\", \"all\")] + [(str(i), str(i)) for i in range(2010, 2020)]\n",
    "year_dropdown = ipywidgets.Dropdown(description=\"Year\", options=years)\n",
    "suffix_dropdown = ipywidgets.Dropdown(description=\"Suffix\")\n",
    "output = ipywidgets.Output()\n",
    "\n",
    "display(year_dropdown)\n",
    "display(suffix_dropdown)\n",
    "display(output)\n",
    "\n",
    "change_guard = False\n",
    "\n",
    "def on_suffix_selection(*args):\n",
    "    global change_guard\n",
    "    if change_guard:\n",
    "        return\n",
    "    output.clear_output(wait=True)\n",
    "    suffix = suffix_dropdown.value\n",
    "    year = year_dropdown.value\n",
    "    with output:\n",
    "        display(plot_entitlement(joined, tracts, suffix, year))\n",
    "\n",
    "def on_year_selection(*args):\n",
    "    global change_guard\n",
    "    if year_dropdown.value == \"all\":\n",
    "        condition = (joined.year >= 2010)\n",
    "    else:\n",
    "        condition = (joined.year == int(year_dropdown.value))\n",
    "    counts = joined[condition].groupby(\"suffix\").agg({\"count\": \"sum\"})[\"count\"]\n",
    "    counts = counts.sort_values(ascending=False)\n",
    "    old_val = suffix_dropdown.value \n",
    "    change_guard=True\n",
    "    suffix_dropdown.options = [\n",
    "        (f\"{name} ({count:,} applications)\", name) \n",
    "        for name,count in zip(counts.index, counts)\n",
    "    ]\n",
    "    if old_val in counts.index:\n",
    "        suffix_dropdown.value = old_val\n",
    "    else:\n",
    "        suffix_dropdown.index = 0\n",
    "    change_guard=False\n",
    "    on_suffix_selection()\n",
    "\n",
    "on_year_selection()\n",
    "suffix_dropdown.observe(on_suffix_selection, names=\"value\")\n",
    "year_dropdown.observe(on_year_selection, names=\"value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
