{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entitlements in TOC-eligible parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import intake\n",
    "import boto3\n",
    "import utils\n",
    "import pcts_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'city-planning-entitlements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcels\n",
    "* Figure out how many are duplicates\n",
    "* Won't know which AINs are used in PCTS, so keep all of them, but have a way to identify how many obs to drop later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    442562\n",
       "1    148994\n",
       "3    110153\n",
       "2     65653\n",
       "4      7844\n",
       "Name: TOC_Tier, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/intermediate/la_parcels_toc.zip')\n",
    "\n",
    "display(parcels.TOC_Tier.value_counts())\n",
    "parcels = parcels[parcels.TOC_Tier > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the centroids and count number of duplicate obs\n",
    "parcels2 = utils.get_centroid(parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels.drop(columns = 'centroid').to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab tables from PCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = catalog.pcts.tCASE.read()\n",
    "app = catalog.pcts.tAPLC.read()\n",
    "geo_info = catalog.pcts.tPROP_GEO_INFO.read()\n",
    "la_prop = catalog.pcts.tLA_PROP.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases1 = cases[['CASE_ID', 'APLC_ID', 'CASE_NBR', 'CASE_SEQ_NBR', 'CASE_YR_NBR', 'CASE_ACTION_ID', 'ADM_ACTION_DT']]\n",
    "app1 = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "geo_info1 = geo_info[['CASE_ID', 'PROP_ID']]\n",
    "la_prop1 = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset cases, keep 2016 and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2 = cases1[cases1.CASE_YR_NBR >= 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with geo_info, la_prop, parcels to ID the parcels that and have entitlements (2016 - after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd.merge(cases2, geo_info1, on = 'CASE_ID', how = 'inner', validate = '1:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pd.merge(m1, la_prop1, on = 'PROP_ID', how = 'inner', validate = 'm:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = pd.merge(m2, parcels, left_on = 'ASSR_PRCL_NBR', right_on = 'AIN', how = 'inner', validate = 'm:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join parcels to zoning and subset to eligible zones\n",
    "* Subset by eligible zones, see how many TOC-eligible parcels also fall into eligible zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning = gpd.read_file(f's3://{bucket_name}/gis/raw/parsed_zoning.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_zones = ['R2', 'R3', 'RAS3', 'R4', 'RAS4', 'R5', \n",
    "                  'RD1.5', 'RD2', 'RD3', 'RD4', 'RD5', 'RD6', \n",
    "                  'C1', 'C2', 'C4', 'C5']\n",
    "\n",
    "eligible_zoning = zoning[zoning.zone_class.isin(eligible_zones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_with_zoning = gpd.sjoin(parcels2, eligible_zoning, how = 'inner', op = 'intersects').drop(columns = ['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in zoning and TOC info about the parcel\n",
    "m4 = pd.merge(m3, parcels_with_zoning, on = ['AIN', 'centroid', 'TOC_Tier'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10700\n",
       "Name: num_obs, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop those that don't have ADM_ACTION_DT\n",
    "# Substitute this later with CASE_ACTION_ID\n",
    "m4 = m4[m4.ADM_ACTION_DT.notna()]\n",
    "\n",
    "# No more duplicates for same parcel geometry after dropping ADM_ACTION_ID NaTs\n",
    "display(m4.num_obs.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in project description\n",
    "m5 = pd.merge(m4, app1, on = 'APLC_ID', how = 'inner', validate = 'm:1')\n",
    "\n",
    "# Drop duplicates\n",
    "m5 = m5.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates for PCTS entitlements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['centroid', 'x', 'y', 'obs', 'num_obs', \n",
    "        'CASE_ID', 'APLC_ID', 'ASSR_PRCL_NBR', 'PROP_ID', \n",
    "        'o1', 'o2', 'o3', 'o1_descrip', 'o2_descrip', 'o3_descrip']\n",
    "\n",
    "m5 = m5.drop(columns = drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new id variable that is just seq number and year. Need a way to get rid of duplicate cases.\n",
    "m5['id'] = m5.CASE_SEQ_NBR.astype(int).astype(str) + '_' + m5.CASE_YR_NBR.astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_we_need = ['id', 'CASE_ACTION_ID', 'ADM_ACTION_DT', 'AIN', 'TOC_Tier', 'ZONE_CMPLT', 'PROJ_DESC_TXT']\n",
    "m6 = m5.drop_duplicates(subset = cols_we_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the PCTS string and grab suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_col_names = ['suffix']\n",
    "\n",
    "def parse_pcts(row):\n",
    "    try:\n",
    "        z = pcts_parser.PCTSCaseNumber(row.CASE_NBR)\n",
    "        return pd.Series([z.suffix], index = parsed_col_names)\n",
    "    except ValueError:\n",
    "        return pd.Series([z.suffix], index = parsed_col_names)\n",
    "\n",
    "parsed = m6.apply(parse_pcts, axis = 1)\n",
    "\n",
    "m6 = pd.concat([m6, parsed], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional subsetting for for TOC-eligible parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag case as TOC or not\n",
    "m6['is_TOC'] = m6.CASE_NBR.str.contains('TOC').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_col = ['CASE_NBR', 'id', 'CASE_ACTION_ID', 'ADM_ACTION_DT', 'AIN', 'TOC_Tier', 'zone_class', \n",
    "           'suffix', 'is_TOC']\n",
    "\n",
    "m6 = m6[keep_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make into parcel level df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m7 = m6.groupby(['AIN', 'TOC_Tier', 'zone_class', 'is_TOC']).agg({'id':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wide\n",
    "m7['num_TOC'] = m7.apply(lambda row: row.id if row.is_TOC == 1 else np.nan, axis = 1) \n",
    "m7['num_nonTOC'] = m7.apply(lambda row: row.id if row.is_TOC == 0 else np.nan, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are multiple obs for the same AIN, fill the NaNs with the max from the other column, so we can just drop duplicates after\n",
    "for col in ['num_TOC', 'num_nonTOC']:\n",
    "    m7[col] = m7[col].fillna(m7.groupby('AIN')[col].transform('max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "m8 = m7.drop_duplicates(subset = ['AIN', 'TOC_Tier', 'zone_class', 'num_TOC', 'num_nonTOC'])\n",
    "\n",
    "for col in ['num_TOC', 'num_nonTOC']:\n",
    "    m8[col] = m8[col].fillna(0).astype(int)\n",
    "\n",
    "m8 = m8.drop(columns = ['is_TOC', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parcels: 2930\n",
      "# parcels with TOC entitlements: 1156\n",
      "# parcels with non TOC entitlements: 1845\n",
      "# parcels with both TOC and non TOC entitlements: 71\n",
      "double check sum: 2930\n"
     ]
    }
   ],
   "source": [
    "toc_parcels = m8[m8.num_TOC > 0]\n",
    "non_toc_parcels = m8[m8.num_nonTOC > 0]\n",
    "have_both_parcels = m8[(m8.num_TOC > 0) & (m8.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(m8)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% parcels with TOC entitlements: 0.3945392491467577\n",
      "% parcels with non TOC entitlements: 0.6296928327645052\n",
      "% parcels with both entitlements: 0.024232081911262797\n"
     ]
    }
   ],
   "source": [
    "print(f'% parcels with TOC entitlements: {len(toc_parcels) / len(m8)}')\n",
    "print(f'% parcels with non TOC entitlements: {len(non_toc_parcels) / len(m8)}')\n",
    "print(f'% parcels with both entitlements: {len(have_both_parcels) / len(m8)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1421\n",
       "1     725\n",
       "2     605\n",
       "4     179\n",
       "Name: TOC_Tier, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m8.TOC_Tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       441\n",
       "R3       358\n",
       "R4       191\n",
       "C4        72\n",
       "RD1.5     46\n",
       "RD2       24\n",
       "R2         7\n",
       "RAS4       5\n",
       "RAS3       4\n",
       "C1         4\n",
       "R5         4\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       607\n",
       "R2       330\n",
       "RD1.5    209\n",
       "RD2      195\n",
       "C4       183\n",
       "R3       160\n",
       "R4        57\n",
       "RD3       54\n",
       "C1        18\n",
       "C5        17\n",
       "R5        15\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9 = pd.merge(m8, parcels2, on = ['AIN', 'TOC_Tier'], how = 'inner').drop(columns = ['x', 'y', 'obs', 'num_obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9.rename(columns = {'centroid':'geometry'}, inplace = True)\n",
    "m9 = gpd.GeoDataFrame(m9)\n",
    "m9.crs = {'init':'epsg:2229'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
