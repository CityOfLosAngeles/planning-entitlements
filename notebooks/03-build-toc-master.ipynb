{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entitlements in TOC-eligible parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'city-planning-entitlements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare methods 1 and 2 to see why parcels with entitlements differ so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original method\n",
    "\"\"\"\n",
    "parcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/intermediate/la_parcels_toc.zip')\n",
    "\n",
    "display(parcels.TOC_Tier.value_counts())\n",
    "parcels = parcels[parcels.TOC_Tier > 0]\n",
    "\n",
    "# Upload just the parcels in TOC Tiers into S3\n",
    "parcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels.geojson', f'{bucket_name}', \n",
    "               'gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcels\n",
    "* Figure out how many are duplicates\n",
    "* Won't know which AINs are used in PCTS, so keep all of them, but have a way to identify how many obs to drop later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/raw/la_parcels.zip')\n",
    "\n",
    "toc_parcels = pd.read_parquet(f's3://{bucket_name}/data/crosswalk_toc2017_parcels.parquet')\n",
    "\n",
    "parcels = pd.merge(parcels, toc_parcels, on = 'AIN', how = 'inner', validate = '1:1').to_crs({'init':'epsg:2229'})\n",
    "display(parcels.TOC_Tier.value_counts())\n",
    "\n",
    "# Upload just the parcels in TOC Tiers into S3\n",
    "parcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson', \n",
    "               f'{bucket_name}', 'gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_withcrosswalk = gpd.read_file(f's3://{bucket_name}/gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\n",
    "# Grab the centroids and count number of duplicate obs\n",
    "parcels2_withcrosswalk = utils.get_centroid(parcels_withcrosswalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = gpd.read_file(f's3://{bucket_name}/gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\n",
    "# Grab the centroids and count number of duplicate obs\n",
    "parcels2 = utils.get_centroid(parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to eligible zones and see which TOC-eligible parcels also fall in eligible zones\n",
    "zoning = gpd.read_file(f's3://{bucket_name}/gis/raw/parsed_zoning.geojson')\n",
    "\n",
    "eligible_zones = ['R2', 'R3', 'RAS3', 'R4', 'RAS4', 'R5', \n",
    "              'RD1.5', 'RD2', 'RD3', 'RD4', 'RD5', 'RD6', \n",
    "              'C1', 'C2', 'C4', 'C5']\n",
    "\n",
    "eligible_zoning = zoning[zoning.zone_class.isin(eligible_zones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_with_zoning = gpd.sjoin(parcels2, eligible_zoning, \n",
    "                            how = 'inner', op = 'intersects').drop(columns = ['index_right'])\n",
    "\n",
    "parcels_with_zoning.to_file(driver = 'GeoJSON', filename = '../gis/parcels_with_zoning.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_with_zoning_withcrosswalk = gpd.sjoin(parcels2_withcrosswalk, eligible_zoning, \n",
    "                                 how = 'inner', op = 'intersects').drop(columns = ['index_right'])\n",
    "\n",
    "parcels_with_zoning_withcrosswalk.to_file(driver = 'GeoJSON', \n",
    "                                          filename = '../gis/parcels_with_zoning_withcrosswalk.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_with_zoning = gpd.read_file('../gis/parcels_with_zoning.geojson').drop_duplicates()\n",
    "parcels_with_zoning_withcrosswalk = gpd.read_file('../gis/parcels_with_zoning_withcrosswalk.geojson').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187017"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_with_zoning.AIN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23350"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_with_zoning_withcrosswalk.AIN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIN</th>\n",
       "      <th>TOC_Tier</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>obs</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>ZONE_CMPLT</th>\n",
       "      <th>ZONE_CLASS1</th>\n",
       "      <th>ZONE_SMRY</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>specific_plan</th>\n",
       "      <th>height_district</th>\n",
       "      <th>D</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>o3</th>\n",
       "      <th>o1_descrip</th>\n",
       "      <th>o2_descrip</th>\n",
       "      <th>o3_descrip</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010004040</td>\n",
       "      <td>1</td>\n",
       "      <td>6.378795e+06</td>\n",
       "      <td>1.908220e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R3-1</td>\n",
       "      <td>R3</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (6378795.418 1908220.195)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024023012</td>\n",
       "      <td>2</td>\n",
       "      <td>6.373280e+06</td>\n",
       "      <td>1.893585e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C4-1VL</td>\n",
       "      <td>C4</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1VL</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (6373279.994 1893585.043)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026008042</td>\n",
       "      <td>2</td>\n",
       "      <td>6.372778e+06</td>\n",
       "      <td>1.893589e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(Q)RD1.5-1</td>\n",
       "      <td>RD1.5</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (6372778.488 1893589.192)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2102002038</td>\n",
       "      <td>1</td>\n",
       "      <td>6.399730e+06</td>\n",
       "      <td>1.901704e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R3-1</td>\n",
       "      <td>R3</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (6399730.096 1901704.165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2102015002</td>\n",
       "      <td>1</td>\n",
       "      <td>6.399758e+06</td>\n",
       "      <td>1.900887e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R3-1</td>\n",
       "      <td>R3</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>POINT (6399758.157 1900886.658)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AIN  TOC_Tier             x             y  obs  num_obs  ZONE_CMPLT  \\\n",
       "0  2010004040         1  6.378795e+06  1.908220e+06    1        1        R3-1   \n",
       "1  2024023012         2  6.373280e+06  1.893585e+06    1        1      C4-1VL   \n",
       "2  2026008042         2  6.372778e+06  1.893589e+06    1        1  (Q)RD1.5-1   \n",
       "3  2102002038         1  6.399730e+06  1.901704e+06    1        1        R3-1   \n",
       "4  2102015002         1  6.399758e+06  1.900887e+06    1        1        R3-1   \n",
       "\n",
       "  ZONE_CLASS1    ZONE_SMRY  Q  ...  specific_plan height_district  D o1  o2  \\\n",
       "0          R3  RESIDENTIAL  0  ...                              1  0          \n",
       "1          C4   COMMERCIAL  0  ...                            1VL  0          \n",
       "2       RD1.5  RESIDENTIAL  1  ...                              1  0          \n",
       "3          R3  RESIDENTIAL  0  ...                              1  0          \n",
       "4          R3  RESIDENTIAL  0  ...                              1  0          \n",
       "\n",
       "  o3 o1_descrip o2_descrip o3_descrip                         geometry  \n",
       "0                                      POINT (6378795.418 1908220.195)  \n",
       "1                                      POINT (6373279.994 1893585.043)  \n",
       "2                                      POINT (6372778.488 1893589.192)  \n",
       "3                                      POINT (6399730.096 1901704.165)  \n",
       "4                                      POINT (6399758.157 1900886.658)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_with_zoning_withcrosswalk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PCTS\n",
    "* Subset and merge together tables within PCTS\n",
    "* Join parcels to zoning\n",
    "* Subset for eligible zones and eligible PCTS prefixes to see how many TOC-eligible parcels fall into eligible zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pcts():\n",
    "    # Grab tables from PCTS\n",
    "    cases = pd.read_parquet('../data/tCASE.parquet')\n",
    "    app = pd.read_parquet('../data/tAPLC.parquet')\n",
    "    geo_info = pd.read_parquet('../data/tPROP_GEO_INFO.parquet')\n",
    "    la_prop = pd.read_parquet('../data/tLA_PROP.parquet')\n",
    "    #cases = catalog.pcts.tCASE.read()\n",
    "    #app = catalog.pcts.tAPLC.read()\n",
    "    #geo_info = catalog.pcts.tPROP_GEO_INFO.read()\n",
    "    #la_prop = catalog.pcts.tLA_PROP.read()\n",
    "    \n",
    "    # Subset dataframes before merging\n",
    "    cases = cases.assign(\n",
    "        # Grab the year-month from received date\n",
    "        CASE_FILE_DATE = pd.to_datetime(cases['CASE_FILE_RCV_DT']).dt.to_period('M'),\n",
    "    )\n",
    "    # Subset to Oct 2017 and after    \n",
    "    cases = cases[cases.CASE_FILE_DATE >= '2017-10'][['CASE_ID', 'APLC_ID', 'CASE_NBR', \n",
    "                                                      'CASE_SEQ_NBR', 'CASE_YR_NBR', 'CASE_ACTION_ID', \n",
    "                                                      'CASE_FILE_RCV_DT', 'CASE_FILE_DATE']]    \n",
    "    \n",
    "    app = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "    geo_info = geo_info[['CASE_ID', 'PROP_ID']]\n",
    "    la_prop = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]\n",
    "    parents = pd.read_parquet(f's3://{bucket_name}/data/intermediate/parent_cases.parquet')\n",
    "\n",
    "    # Merge in parent cases\n",
    "    cases2 = pd.merge(cases, parents, on = 'CASE_ID', how = 'inner', validate = '1:1')\n",
    "    \n",
    "    # Merge with geo_info, la_prop, parcels to ID the parcels that have entitlements (10/2017 and after)\n",
    "    m1 = pd.merge(cases2, geo_info, on = 'CASE_ID', how = 'inner', validate = '1:m')\n",
    "    m2 = pd.merge(m1, la_prop, on = 'PROP_ID', how = 'inner', validate = 'm:1')\n",
    "    m3 = pd.merge(m2, parcels, left_on = 'ASSR_PRCL_NBR', right_on = 'AIN', how = 'inner', validate = 'm:1')\n",
    "    m4 = pd.merge(m3, app, on = 'APLC_ID', how = 'left', validate = 'm:1')\n",
    "    \n",
    "    m4 = m4.assign(\n",
    "        id = m4.CASE_SEQ_NBR.astype(int).astype(str) + '_' + m4.CASE_YR_NBR.astype(int).astype(str)\n",
    "    )  \n",
    "  \n",
    "    m4 = m4.drop_duplicates(subset = ['id', 'CASE_FILE_DATE', 'AIN', 'TOC_Tier', 'PROJ_DESC_TXT'])\n",
    "\n",
    "    return m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoning_pcts_processing(df, parcels_with_zoning): \n",
    "    # Merge in zoning and TOC info about the parcel\n",
    "    m1 = pd.merge(df, parcels_with_zoning, on = ['AIN', 'centroid', 'TOC_Tier'], how = 'inner')\n",
    "    \n",
    "    # Drop duplicates\n",
    "    m1 = m1.drop_duplicates()\n",
    "\n",
    "    # Parse PCTS string and grab prefix\n",
    "    parsed_col_names = ['prefix']\n",
    "\n",
    "    def parse_pcts(row):\n",
    "        try:\n",
    "            z = utils.PCTSCaseNumber(row.CASE_NBR)\n",
    "            return pd.Series([z.prefix], index = parsed_col_names)\n",
    "        except ValueError:\n",
    "            return pd.Series([z.prefix], index = parsed_col_names)\n",
    "\n",
    "    parsed = m1.apply(parse_pcts, axis = 1)\n",
    "    m2 = pd.concat([m1, parsed], axis = 1)\n",
    "    \n",
    "   \n",
    "    # Subset by PCTS prefix, drop ENV/ADM/PAR cases\n",
    "    drop_prefix = ['ENV', 'ADM', 'PAR']\n",
    "    m3 = m2.loc[~m2.prefix.isin(drop_prefix)]\n",
    "    \n",
    "    # Subset by CASE_ACTION_ID -- let's use all cases for now (but approved cases are 1, 2, 11)\n",
    "\n",
    "    # At this point, no more duplicates by PARENT_CASE - AIN combination\n",
    "    return m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_toc_entitlements(df):\n",
    "    keep_col = ['CASE_NBR', 'id', 'CASE_ACTION_ID', 'CASE_FILE_DATE', \n",
    "            'AIN', 'TOC_Tier', 'zone_class']\n",
    "    \n",
    "    df = (df[keep_col]\n",
    "          .assign(is_TOC = df.CASE_NBR.str.contains('TOC').astype(int))\n",
    "         )\n",
    "    \n",
    "    # Make into parcel-level df\n",
    "    df2 = (df.groupby(['AIN', 'TOC_Tier', 'zone_class', 'is_TOC'])\n",
    "           .agg({'id':'count'})\n",
    "           .reset_index()) \n",
    "\n",
    "    # Make wide\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.apply(lambda row: row.id if row.is_TOC == 1 else np.nan, axis = 1),\n",
    "        num_nonTOC = df2.apply(lambda row: row.id if row.is_TOC == 0 else np.nan, axis = 1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # If there are multiple obs for the same AIN, fill the NaNs with the max from the other column \n",
    "    # Then, drop duplicates\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.num_TOC.fillna(df2.groupby('AIN')['num_TOC'].transform('max')),\n",
    "        num_nonTOC = df2.num_nonTOC.fillna(df2.groupby('AIN')['num_nonTOC'].transform('max'))\n",
    "    )\n",
    "    \n",
    "    df3 = df2.drop_duplicates(subset = ['AIN', 'TOC_Tier', 'zone_class', 'num_TOC', 'num_nonTOC'])\n",
    "\n",
    "    df3 = (df3.assign(\n",
    "            num_TOC = df3.num_TOC.fillna(0).astype(int),\n",
    "            num_nonTOC = df3.num_nonTOC.fillna(0).astype(int)\n",
    "        ).drop(columns = ['is_TOC', 'id'])\n",
    "    )\n",
    "    \n",
    "    # Merge in centroids for these parcels (much easier to plot)\n",
    "    df4 = pd.merge(df3, parcels2, on = ['AIN', 'TOC_Tier'], how = 'inner').drop(\n",
    "                    columns = ['x', 'y', 'obs', 'num_obs'])\n",
    "    \n",
    "    df4.rename(columns = {'centroid':'geometry'}, inplace = True)\n",
    "    df4 = gpd.GeoDataFrame(df4)\n",
    "    df4.crs = {'init':'epsg:2229'}\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts1 = merge_pcts(parcels_with_zoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts11 = merge_pcts(parcels_with_zoning_withcrosswalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts2 = zoning_pcts_processing(pcts1, parcels_with_zoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9ee6806e0d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpcts22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzoning_pcts_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcts2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparcels_with_zoning_withcrosswalk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-2d4420b13f5f>\u001b[0m in \u001b[0;36mzoning_pcts_processing\u001b[0;34m(df, parcels_with_zoning)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdrop_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ENV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PAR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#m3 = m2.loc[~m2.prefix.isin(drop_prefix)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ENV\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ADM\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"PAR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Subset by CASE_ACTION_ID -- let's use all cases for now (but approved cases are 1, 2, 11)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2980\u001b[0m         \u001b[0;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_frame\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must pass DataFrame with boolean values only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   9274\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9275\u001b[0m         return self._where(\n\u001b[0;32m-> 9276\u001b[0;31m             \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9277\u001b[0m         )\n\u001b[1;32m   9278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[1;32m   9121\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9122\u001b[0m                 \u001b[0mtry_cast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9123\u001b[0;31m                 \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9124\u001b[0m             )\n\u001b[1;32m   9125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"where\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maligned_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_info_axis_number\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3974\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3975\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3976\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3978\u001b[0m     def drop(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4513\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4514\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4515\u001b[0m         ).__finalize__(self)\n\u001b[1;32m   4516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   3856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3857\u001b[0m             frame = frame._reindex_columns(\n\u001b[0;32m-> 3858\u001b[0;31m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3859\u001b[0m             )\n\u001b[1;32m   3860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_columns\u001b[0;34m(self, new_columns, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   3904\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3905\u001b[0m             \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3906\u001b[0;31m             \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3907\u001b[0m         )\n\u001b[1;32m   3908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4575\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4576\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4577\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4578\u001b[0m             )\n\u001b[1;32m   4579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3362\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "pcts22 = zoning_pcts_processing(pcts2, parcels_with_zoning_withcrosswalk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts3 = tag_toc_entitlements(pcts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts33 = tag_toc_entitlements(pcts22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_parcels = pcts3[pcts3.num_TOC > 0]\n",
    "non_toc_parcels = pcts3[pcts3.num_nonTOC > 0]\n",
    "have_both_parcels = pcts3[(pcts3.num_TOC > 0) & (pcts3.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(pcts3)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_parcels = pcts33[pcts33.num_TOC > 0]\n",
    "non_toc_parcels = pcts33[pcts33.num_nonTOC > 0]\n",
    "have_both_parcels = pcts33[(pcts33.num_TOC > 0) & (pcts33.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(pcts33)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_parcels = df[df.num_TOC > 0]\n",
    "non_toc_parcels = df[df.num_nonTOC > 0]\n",
    "have_both_parcels = df[(df.num_TOC > 0) & (df.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(df)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% parcels with TOC entitlements: {len(toc_parcels) / len(df)}')\n",
    "print(f'% parcels with non TOC entitlements: {len(non_toc_parcels) / len(df)}')\n",
    "print(f'% parcels with both entitlements: {len(have_both_parcels) / len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TOC_Tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "m12.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson', \n",
    "               f'{bucket_name}', 'gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by TOC Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "m13 = m12.groupby('TOC_Tier').agg({'AIN':'count', 'num_TOC':'sum', 'num_nonTOC':'sum'}).reset_index()\n",
    "\n",
    "for i in ['TOC', 'nonTOC']:\n",
    "    new_col = f'pct_{i}'\n",
    "    numerator = f'num_{i}'\n",
    "    m13[new_col] = m13[numerator] / (m13.num_TOC + m13.num_nonTOC)\n",
    "    \n",
    "m13['all_AIN'] = m13.AIN.sum()\n",
    "m13['pct_AIN'] = m13.AIN / m13.all_AIN\n",
    "\n",
    "m13\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by Zone Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "m14 = m12.groupby('zone_class').agg({'AIN': 'count', 'num_TOC': 'sum', 'num_nonTOC': 'sum'}).reset_index()\n",
    "\n",
    "for i in ['TOC', 'nonTOC']:\n",
    "    new_col = f'pct_{i}'\n",
    "    numerator = f'num_{i}'\n",
    "    m14[new_col] = m14[numerator] / (m14.num_TOC + m14.num_nonTOC)\n",
    "    \n",
    "m14['all_AIN'] = m14.AIN.sum()\n",
    "m14['pct_AIN'] = m14.AIN / m14.all_AIN\n",
    "\n",
    "m14\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "writer = pd.ExcelWriter('../outputs/toc_charts.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "m13.to_excel(writer, sheet_name = 'entitlements_by_tier')\n",
    "m14.to_excel(writer, sheet_name = 'entitlements_by_zone')\n",
    "\n",
    "writer.save()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
