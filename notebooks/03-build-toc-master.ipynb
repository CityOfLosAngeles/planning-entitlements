{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entitlements in TOC-eligible parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import intake\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pcts_parser\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'city-planning-entitlements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcels\n",
    "* Won't know which AINs are used in PCTS, so keep all of them, but have a way to identify how many obs to drop later on\n",
    "* 5/26: when we switched out our spatially joined toc-eligible parcels with the crosswalk of toc-eligible parcels, the total number of eligible parcels dropped by a lot. The crosswalk is about 12% the size of the original one (which albeit, would have shrunk once we accounted for zoning). But once parent are attached parcels and a parcel-level df is constructed, we went from 200 parcels to about 50 parcels. \n",
    "* 5/28: let's just use our file first, until we get confirmation from Planning. But, simply cleaning up this notebook and using functions...we are able to reproduce the results we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" NEW METHOD\\nparcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/raw/la_parcels.zip')\\n\\ntoc_parcels = pd.read_parquet(f's3://{bucket_name}/data/crosswalk_toc2017_parcels.parquet')\\n\\nparcels = pd.merge(parcels, toc_parcels, on = 'AIN', how = 'inner', validate = '1:1').to_crs({'init':'epsg:2229'})\\ndisplay(parcels.TOC_Tier.value_counts())\\n\\n# Upload just the parcels in TOC Tiers into S3\\nparcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\\n\\ns3.upload_file('../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson', \\n               f'{bucket_name}', 'gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NEW METHOD\n",
    "parcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/raw/la_parcels.zip')\n",
    "\n",
    "toc_parcels = pd.read_parquet(f's3://{bucket_name}/data/crosswalk_toc2017_parcels.parquet')\n",
    "\n",
    "parcels = pd.merge(parcels, toc_parcels, on = 'AIN', how = 'inner', validate = '1:1').to_crs({'init':'epsg:2229'})\n",
    "display(parcels.TOC_Tier.value_counts())\n",
    "\n",
    "# Upload just the parcels in TOC Tiers into S3\n",
    "parcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson', \n",
    "               f'{bucket_name}', 'gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" NEW METHOD\\nparcels = gpd.read_file(f's3://{bucket_name}/gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\\n\\n# Grab the centroids and count number of duplicate obs\\nparcels2 = utils.get_centroid(parcels)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NEW METHOD\n",
    "parcels = gpd.read_file(f's3://{bucket_name}/gis/intermediate/toc_eligible_parcels_withcrosswalk.geojson')\n",
    "\n",
    "# Grab the centroids and count number of duplicate obs\n",
    "parcels2 = utils.get_centroid(parcels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ORIGINAL METHOD\\nparcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/intermediate/la_parcels_toc.zip')\\n\\nparcels = parcels[parcels.TOC_Tier > 0]\\n\\n# Upload just the parcels in TOC Tiers into S3\\nparcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels.geojson')\\n\\ns3.upload_file('../gis/intermediate/toc_eligible_parcels.geojson', f'{bucket_name}', \\n               'gis/intermediate/toc_eligible_parcels.geojson')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ORIGINAL METHOD\n",
    "parcels = gpd.read_file(f'zip+s3://{bucket_name}/gis/intermediate/la_parcels_toc.zip')\n",
    "\n",
    "parcels = parcels[parcels.TOC_Tier > 0]\n",
    "\n",
    "# Upload just the parcels in TOC Tiers into S3\n",
    "parcels.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels.geojson', f'{bucket_name}', \n",
    "               'gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts = pd.read_parquet(f's3://{bucket_name}/data/final/master_pcts.parquet')\n",
    "pcts = pcts[(pcts.CASE_FILE_DATE >= '2017-10') & \n",
    "            (pcts.CASE_ID == pcts.PARENT_CASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "parcels = gpd.read_file(f's3://{bucket_name}/gis/intermediate/toc_eligible_parcels.geojson')\n",
    "\n",
    "# Grab the centroids and count number of duplicate obs\n",
    "parcels2 = utils.get_centroid(parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to eligible zones and see which TOC-eligible parcels also fall in eligible zones\n",
    "zoning = gpd.read_file(f's3://{bucket_name}/gis/raw/parsed_zoning.geojson')\n",
    "\n",
    "eligible_zones = ['R2', 'R3', 'RAS3', 'R4', 'RAS4', 'R5', \n",
    "              'RD1.5', 'RD2', 'RD3', 'RD4', 'RD5', 'RD6', \n",
    "              'C1', 'C2', 'C4', 'C5']\n",
    "\n",
    "eligible_zoning = zoning[zoning.zone_class.isin(eligible_zones)]\n",
    "\n",
    "parcels_with_zoning = gpd.sjoin(parcels2, eligible_zoning, \n",
    "                                how = 'inner', op = 'intersects').drop(columns = ['index_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PCTS\n",
    "* Join parcels to zoning\n",
    "* Subset for eligible zones and eligible PCTS prefixes to see how many TOC-eligible parcels fall into eligible zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoning_pcts_processing(df, parcels_with_zoning): \n",
    "    # Merge in zoning and TOC info about the parcel\n",
    "    m1 = pd.merge(df, parcels_with_zoning, on = ['AIN'], how = 'inner')\n",
    "    \n",
    "    # Drop duplicates\n",
    "    m1 = m1.drop_duplicates()\n",
    "\n",
    "    # Parse PCTS string and grab prefix\n",
    "    parsed_col_names = ['prefix']\n",
    "\n",
    "    def parse_pcts(row):\n",
    "        try:\n",
    "            z = pcts_parser.PCTSCaseNumber(row.CASE_NBR)\n",
    "            return pd.Series([z.prefix], index = parsed_col_names)\n",
    "        except ValueError:\n",
    "            return pd.Series([z.prefix], index = parsed_col_names)\n",
    "\n",
    "    parsed = m1.apply(parse_pcts, axis = 1)\n",
    "    m2 = pd.concat([m1, parsed], axis = 1)\n",
    "    \n",
    "   \n",
    "    # Subset by PCTS prefix, drop ENV/ADM/PAR cases\n",
    "    drop_prefix = ['ENV', 'ADM', 'PAR']\n",
    "    m3 = m2.loc[~m2.prefix.isin(drop_prefix)]\n",
    "    \n",
    "    # Subset by CASE_ACTION_ID -- let's use all cases for now (but approved cases are 1, 2, 11)\n",
    "    approved_cases = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    m4 = m3.loc[m3.CASE_ACTION_ID.isin(approved_cases)]\n",
    "        \n",
    "    # At this point, no more duplicates by PARENT_CASE - AIN combination\n",
    "    return m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_toc_entitlements(df):\n",
    "    keep_col = ['CASE_NBR', 'id', 'CASE_ACTION_ID', 'CASE_FILE_DATE', \n",
    "            'AIN', 'TOC_Tier', 'zone_class']\n",
    "    \n",
    "    df = (df[keep_col]\n",
    "          .assign(is_TOC = df.CASE_NBR.str.contains('TOC').astype(int))\n",
    "         )\n",
    "    \n",
    "    # Make into parcel-level df\n",
    "    df2 = (df.groupby(['AIN', 'TOC_Tier', 'zone_class', 'is_TOC'])\n",
    "           .agg({'id':'count'})\n",
    "           .reset_index()) \n",
    "\n",
    "    # Make wide\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.apply(lambda row: row.id if row.is_TOC == 1 else np.nan, axis = 1),\n",
    "        num_nonTOC = df2.apply(lambda row: row.id if row.is_TOC == 0 else np.nan, axis = 1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # If there are multiple obs for the same AIN, fill the NaNs with the max from the other column \n",
    "    # Then, drop duplicates\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.num_TOC.fillna(df2.groupby('AIN')['num_TOC'].transform('max')),\n",
    "        num_nonTOC = df2.num_nonTOC.fillna(df2.groupby('AIN')['num_nonTOC'].transform('max'))\n",
    "    )\n",
    "    \n",
    "    df3 = df2.drop_duplicates(subset = ['AIN', 'TOC_Tier', 'zone_class', 'num_TOC', 'num_nonTOC'])\n",
    "\n",
    "    df3 = (df3.assign(\n",
    "            num_TOC = df3.num_TOC.fillna(0).astype(int),\n",
    "            num_nonTOC = df3.num_nonTOC.fillna(0).astype(int)\n",
    "        ).drop(columns = ['is_TOC', 'id'])\n",
    "    )\n",
    "    \n",
    "    # Merge in centroids for these parcels (much easier to plot)\n",
    "    df4 = pd.merge(df3, parcels2, on = ['AIN', 'TOC_Tier'], how = 'inner').drop(\n",
    "                    columns = ['x', 'y', 'obs', 'num_obs'])\n",
    "    \n",
    "    df4.rename(columns = {'centroid':'geometry'}, inplace = True)\n",
    "    df4 = gpd.GeoDataFrame(df4)\n",
    "    df4.crs = {'init':'epsg:2229'}\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts2 = zoning_pcts_processing(pcts, parcels_with_zoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "df = tag_toc_entitlements(pcts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parcels: 1219\n",
      "# parcels with TOC entitlements: 234\n",
      "# parcels with non TOC entitlements: 1004\n",
      "# parcels with both TOC and non TOC entitlements: 19\n",
      "double check sum: 1219\n"
     ]
    }
   ],
   "source": [
    "toc_parcels = df[df.num_TOC > 0]\n",
    "non_toc_parcels = df[df.num_nonTOC > 0]\n",
    "have_both_parcels = df[(df.num_TOC > 0) & (df.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(df)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% parcels with TOC entitlements: 0.19196062346185397\n",
      "% parcels with non TOC entitlements: 0.8236259228876128\n",
      "% parcels with both entitlements: 0.015586546349466776\n"
     ]
    }
   ],
   "source": [
    "print(f'% parcels with TOC entitlements: {len(toc_parcels) / len(df)}')\n",
    "print(f'% parcels with non TOC entitlements: {len(non_toc_parcels) / len(df)}')\n",
    "print(f'% parcels with both entitlements: {len(have_both_parcels) / len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       86\n",
       "R3       73\n",
       "R4       50\n",
       "C4       13\n",
       "RD1.5     6\n",
       "R5        2\n",
       "RAS4      2\n",
       "RD2       1\n",
       "R2        1\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       420\n",
       "C4       166\n",
       "R3       107\n",
       "RD1.5     91\n",
       "R2        74\n",
       "RD2       60\n",
       "R4        30\n",
       "C5        17\n",
       "C1        13\n",
       "RD3       10\n",
       "R5         9\n",
       "RAS4       6\n",
       "RD5        1\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_file(driver = 'GeoJSON', filename = '../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson', \n",
    "               f'{bucket_name}', 'gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by TOC Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOC_Tier</th>\n",
       "      <th>AIN</th>\n",
       "      <th>num_TOC</th>\n",
       "      <th>num_nonTOC</th>\n",
       "      <th>pct_TOC</th>\n",
       "      <th>pct_nonTOC</th>\n",
       "      <th>all_AIN</th>\n",
       "      <th>pct_AIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>31</td>\n",
       "      <td>279</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.229696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>55</td>\n",
       "      <td>203</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>0.786822</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.204266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>591</td>\n",
       "      <td>138</td>\n",
       "      <td>520</td>\n",
       "      <td>0.209726</td>\n",
       "      <td>0.790274</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.484824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>137</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.925676</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.081214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOC_Tier  AIN  num_TOC  num_nonTOC   pct_TOC  pct_nonTOC  all_AIN   pct_AIN\n",
       "0         1  280       31         279  0.100000    0.900000     1219  0.229696\n",
       "1         2  249       55         203  0.213178    0.786822     1219  0.204266\n",
       "2         3  591      138         520  0.209726    0.790274     1219  0.484824\n",
       "3         4   99       11         137  0.074324    0.925676     1219  0.081214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_by_tiers(df):\n",
    "    df2 = df.groupby('TOC_Tier').agg({'AIN':'count', 'num_TOC':'sum', 'num_nonTOC':'sum'}).reset_index()\n",
    "    \n",
    "    for i in ['TOC', 'nonTOC']:\n",
    "        new_col = f'pct_{i}'\n",
    "        numerator = f'num_{i}'\n",
    "        df2[new_col] = df2[numerator] / (df2.num_TOC + df2.num_nonTOC)\n",
    "    \n",
    "    df2['all_AIN'] = df2.AIN.sum()\n",
    "    df2['pct_AIN'] = df2.AIN / df2.all_AIN\n",
    "    \n",
    "    return df2\n",
    "\n",
    "by_tiers = summarize_by_tiers(df)\n",
    "by_tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by Zone Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_class</th>\n",
       "      <th>AIN</th>\n",
       "      <th>num_TOC</th>\n",
       "      <th>num_nonTOC</th>\n",
       "      <th>pct_TOC</th>\n",
       "      <th>pct_nonTOC</th>\n",
       "      <th>all_AIN</th>\n",
       "      <th>pct_AIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.010664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2</td>\n",
       "      <td>495</td>\n",
       "      <td>87</td>\n",
       "      <td>481</td>\n",
       "      <td>0.153169</td>\n",
       "      <td>0.846831</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.406071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4</td>\n",
       "      <td>177</td>\n",
       "      <td>13</td>\n",
       "      <td>211</td>\n",
       "      <td>0.058036</td>\n",
       "      <td>0.941964</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.145201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.013946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.060705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R3</td>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>114</td>\n",
       "      <td>0.390374</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.145201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R4</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.064807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.009024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAS4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.006563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1.5</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.078753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.050041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_class  AIN  num_TOC  num_nonTOC   pct_TOC  pct_nonTOC  all_AIN  \\\n",
       "0          C1   13        0          14  0.000000    1.000000     1219   \n",
       "1          C2  495       87         481  0.153169    0.846831     1219   \n",
       "2          C4  177       13         211  0.058036    0.941964     1219   \n",
       "3          C5   17        0          20  0.000000    1.000000     1219   \n",
       "4          R2   74        1          78  0.012658    0.987342     1219   \n",
       "5          R3  177       73         114  0.390374    0.609626     1219   \n",
       "6          R4   79       50          31  0.617284    0.382716     1219   \n",
       "7          R5   11        2          10  0.166667    0.833333     1219   \n",
       "8        RAS4    8        2           7  0.222222    0.777778     1219   \n",
       "9       RD1.5   96        6          99  0.057143    0.942857     1219   \n",
       "10        RD2   61        1          62  0.015873    0.984127     1219   \n",
       "11        RD3   10        0          11  0.000000    1.000000     1219   \n",
       "12        RD5    1        0           1  0.000000    1.000000     1219   \n",
       "\n",
       "     pct_AIN  \n",
       "0   0.010664  \n",
       "1   0.406071  \n",
       "2   0.145201  \n",
       "3   0.013946  \n",
       "4   0.060705  \n",
       "5   0.145201  \n",
       "6   0.064807  \n",
       "7   0.009024  \n",
       "8   0.006563  \n",
       "9   0.078753  \n",
       "10  0.050041  \n",
       "11  0.008203  \n",
       "12  0.000820  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_by_zones(df):\n",
    "    df2 = df.groupby('zone_class').agg({'AIN':'count', 'num_TOC':'sum', 'num_nonTOC':'sum'}).reset_index()\n",
    "    \n",
    "    for i in ['TOC', 'nonTOC']:\n",
    "        new_col = f'pct_{i}'\n",
    "        numerator = f'num_{i}'\n",
    "        df2[new_col] = df2[numerator] / (df2.num_TOC + df2.num_nonTOC)\n",
    "    \n",
    "    df2['all_AIN'] = df2.AIN.sum()\n",
    "    df2['pct_AIN'] = df2.AIN / df2.all_AIN\n",
    "    \n",
    "    return df2\n",
    "\n",
    "by_zones = summarize_by_zones(df)\n",
    "by_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../outputs/toc_charts.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "by_tiers.to_excel(writer, sheet_name = 'entitlements_by_tier')\n",
    "by_zones.to_excel(writer, sheet_name = 'entitlements_by_zone')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
