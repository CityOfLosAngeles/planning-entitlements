{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entitlements in TOC-eligible parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import geopandas as gpd\n",
    "import intake\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import utils\n",
    "import laplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_catalog(\"../catalogs/*.yml\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'city-planning-entitlements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PCTS\n",
    "* Won't know which AINs are used in PCTS. Keep all the CASE_NBR-AINs but have a way to identify how many obs to drop later on\n",
    "* Join parcels to zoning eligible zones\n",
    "* Want all the entitlements (TOC or non-TOC) after 10/2017 in the TOC-eligible parcels, and then we can see what activity has occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_pcts():   \n",
    "    # Import PCTS - use function to subset\n",
    "    pcts = catalog.pcts2.read()\n",
    "    \n",
    "    FULL_PREFIX = list(laplan.pcts.VALID_PCTS_PREFIX)\n",
    "    remove_prefix = [\"ENV\", \"PAR\", \"ADM\"]\n",
    "    prefix = [x for x in FULL_PREFIX if x not in remove_prefix]\n",
    "\n",
    "    pcts = laplan.pcts.subset_pcts(\n",
    "        pcts,\n",
    "        start_date=\"2017-10-01\",\n",
    "        prefix_list=prefix,\n",
    "        get_dummies=True,\n",
    "    )\n",
    "    \n",
    "    pcts = laplan.pcts.drop_child_cases(pcts, keep_child_entitlements = True)\n",
    "    \n",
    "    dropme = prefix_suffix_cols = prefix + list(laplan.pcts.VALID_PCTS_SUFFIX)\n",
    "    pcts = pcts.drop(columns = dropme)\n",
    "    \n",
    "    # Import parcels\n",
    "    parcels = catalog.toc_parcels.read().to_crs(\"EPSG:2229\")\n",
    "    \n",
    "    # Grab the centroids and count number of duplicate obs\n",
    "    parcels2 = utils.get_centroid(parcels)\n",
    "    \n",
    "    # geoparquets can't be read from S3 directly. Download and read locally.\n",
    "    zoning_file = \"parsed_zoning.parquet\"\n",
    "    s3.download_file(f'{bucket_name}',\n",
    "                     f'gis/raw/{zoning_file}', f'../gis/{zoning_file}')\n",
    "\n",
    "    zoning = gpd.read_parquet(f'../gis/{zoning_file}').to_crs(\"EPSG:2229\")\n",
    "    os.remove(f'../gis/{zoning_file}')\n",
    "    \n",
    "    eligible_zones = ['R2', 'R3', 'RAS3', 'R4', 'RAS4', 'R5', \n",
    "                  'RD1.5', 'RD2', 'RD3', 'RD4', 'RD5', 'RD6', \n",
    "                  'C1', 'C2', 'C4', 'C5']\n",
    "\n",
    "    eligible_zoning = zoning[zoning.zone_class.isin(eligible_zones)]\n",
    "\n",
    "        \n",
    "    # Merge PCTS with parcel info to see which TOC Tier it falls within\n",
    "    m1 = pd.merge(parcels2, pcts, on = 'AIN', how = 'inner', validate = '1:m')   \n",
    "\n",
    "    # Spatial join with eligible zones and attach the zoning info\n",
    "    m2 = gpd.sjoin(m1, eligible_zoning, how = 'inner', op = 'intersects').drop(columns = ['index_right'])\n",
    "\n",
    "    m2 = m2.drop_duplicates()\n",
    "        \n",
    "    return m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_pcts_processing(df): \n",
    "    # We care about TOC vs non-TOC entitlements\n",
    "    df = df.assign(\n",
    "        is_TOC = df.CASE_NBR.str.contains(\"TOC\").astype(int),\n",
    "    )\n",
    "    \n",
    "    # Subset by CASE_ACTION_ID -- let's use all cases for now (but approved cases are 1, 2, 11)\n",
    "    # We have some NaN CASE_ACTION_IDs, so we won't subset at all\n",
    "    \n",
    "    # At this point, no more duplicates by PARENT_CASE - AIN combination\n",
    "    \n",
    "    # But, there are cases that apply to lots of parcels\n",
    "    # Drop cases that apply to 20+ parcels (6 cases, which are all non-TOC cases)\n",
    "    big_cases = (df.groupby('CASE_ID')\n",
    "                 .agg({'id': 'count'})\n",
    "                 .reset_index()\n",
    "                )\n",
    "    \n",
    "    big_cases = big_cases[big_cases['id'] >= 20]\n",
    "    df = df[~df.CASE_ID.isin(big_cases.CASE_ID)]\n",
    "    \n",
    "    # Subset and keep colums we need\n",
    "    keep = ['CASE_ID', 'AIN', 'TOC_Tier', \n",
    "            'CASE_NBR', 'CASE_SEQ_NBR', 'CASE_YR_NBR', 'id', \n",
    "            'CASE_ACTION_ID', 'CASE_FILE_RCV_DT', 'CASE_FILE_DATE', \n",
    "            'PARENT_CASE', 'PROJ_DESC_TXT',\n",
    "            'zone_class', 'centroid', 'is_TOC']\n",
    "    \n",
    "    return df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parcel_level_df(df):\n",
    "    \"\"\"\n",
    "    Ignore the fact that the same case can touch multiple parcels...\n",
    "    TOC Tiers analysis will naturally count multiple times, because tiers coming from\n",
    "    bus stops or rail lines will all overlap each other. \n",
    "    That analysis uses parcel-level PCTS combined with transit-stop-level TOC Tiers info.\n",
    "    \n",
    "    Reshape and make a parcel-level df to be used in later notebooks.\n",
    "    Create the toc_parcels_with_entitlements.geojson file.\n",
    "    \"\"\"\n",
    "    # Save the geometry of the parcels, just use centroids\n",
    "    parcel_centroids = df[['AIN', 'centroid']].drop_duplicates()\n",
    "    \n",
    "    keep_col = ['CASE_NBR', 'CASE_ID', 'CASE_ACTION_ID', 'CASE_FILE_DATE', \n",
    "                'AIN', 'TOC_Tier', 'zone_class', 'is_TOC']\n",
    "    \n",
    "    df = df[keep_col]\n",
    "         \n",
    "    # Make into parcel-level df\n",
    "    df2 = (df.groupby(['AIN', 'TOC_Tier', 'zone_class', 'is_TOC'])\n",
    "           .agg({'CASE_ID':'count'})\n",
    "           .rename(columns = {'CASE_ID': 'num_cases'})\n",
    "           .reset_index()) \n",
    "\n",
    "    # Make wide\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.apply(lambda row: row.num_cases if row.is_TOC == 1 else np.nan, axis = 1),\n",
    "        num_nonTOC = df2.apply(lambda row: row.num_cases if row.is_TOC == 0 else np.nan, axis = 1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # If there are multiple obs for the same AIN, fill the NaNs with the max from the other column \n",
    "    # Then, drop duplicates\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.num_TOC.fillna(df2.groupby('AIN')['num_TOC'].transform('max')),\n",
    "        num_nonTOC = df2.num_nonTOC.fillna(df2.groupby('AIN')['num_nonTOC'].transform('max'))\n",
    "    )\n",
    "    \n",
    "    df3 = df2.drop_duplicates(subset = ['AIN', 'TOC_Tier', 'zone_class', 'num_TOC', 'num_nonTOC'])\n",
    "\n",
    "    df3 = (df3.assign(\n",
    "            num_TOC = df3.num_TOC.fillna(0).astype(int),\n",
    "            num_nonTOC = df3.num_nonTOC.fillna(0).astype(int)\n",
    "        ).drop(columns = ['is_TOC', 'num_cases'])\n",
    "    )\n",
    "\n",
    "    # Merge geometry back on\n",
    "    df4 = pd.merge(parcel_centroids, df3, on = 'AIN', how = 'inner', validate = '1:m')\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_to_tract_tier_zone(df):\n",
    "    crosswalk_parcels_tracts = catalog.crosswalk_parcels_tracts.read()\n",
    "    \n",
    "    with_tract = pd.merge(df, crosswalk_parcels_tracts[[\"AIN\", \"GEOID\"]], \n",
    "         on = [\"AIN\"], how = \"left\", validate = \"m:1\")\n",
    "    \n",
    "    # Tag TOC entitlements, but make sure it's unique cases at the tract-tier-zone level\n",
    "    with_tract['obs'] = with_tract.groupby([\"CASE_ID\", \"GEOID\", \"TOC_Tier\"]).cumcount() + 1\n",
    "    with_tract['max_obs'] = with_tract.groupby([\"CASE_ID\", \"GEOID\", \"TOC_Tier\"])[\"obs\"].transform(\"max\")\n",
    "    \n",
    "    # So a CASE_ID can be applied up to 9 different AINs within the same tract-tier-zone.\n",
    "    print('# parcels applied for each CASE_ID')\n",
    "    print(with_tract.max_obs.value_counts())\n",
    "    \n",
    "    # Only keep 1 case for each tract-tier-zone\n",
    "    keep_cols = [\"CASE_ID\", \"TOC_Tier\", \"GEOID\", \"CASE_NBR\", \n",
    "                 \"CASE_SEQ_NBR\", \"CASE_YR_NBR\", \n",
    "                 \"CASE_ACTION_ID\", \"CASE_FILE_RCV_DT\", \"CASE_FILE_DATE\", \n",
    "                 \"PARENT_CASE\", \"PROJ_DESC_TXT\", \"zone_class\", \"is_TOC\"]\n",
    "    \n",
    "    unique_case = (with_tract[keep_cols].drop_duplicates()\n",
    "                   .reset_index(drop=True)\n",
    "                  )\n",
    "    \n",
    "    unique_case['obs'] = unique_case.groupby([\"CASE_ID\", \"GEOID\"]).cumcount() + 1\n",
    "    unique_case['max_obs'] = unique_case.groupby([\"CASE_ID\", \"GEOID\"])[\"obs\"].transform(\"max\")\n",
    "    \n",
    "    # So a CASE_ID can be applied up to 3 different tiers within the same tract.\n",
    "    print('# tiers applied for each CASE_ID')\n",
    "    print(unique_case.max_obs.value_counts())    \n",
    "    \n",
    "    unique_case = unique_case.drop(columns = ['obs', 'max_obs'])\n",
    "    \n",
    "    \n",
    "    # Get counts of num_TOC and num_nonTOC by tract-tiers-zone\n",
    "    df1 = (unique_case.groupby(['GEOID', 'TOC_Tier', 'is_TOC', 'zone_class'])\n",
    "                .agg({'CASE_ID': 'count'})\n",
    "                .rename(columns = {'CASE_ID': 'num_cases'})\n",
    "                .reset_index()\n",
    "               )\n",
    "\n",
    "    # Make wide\n",
    "    df2 = df1.assign(\n",
    "        num_TOC = df1.apply(lambda row: row.num_cases if row.is_TOC == 1 else np.nan, axis = 1),\n",
    "        num_nonTOC = df1.apply(lambda row: row.num_cases if row.is_TOC == 0 else np.nan, axis = 1)\n",
    "    )\n",
    "    \n",
    "    # If there are multiple obs for the same tract-tier-zone, fill the NaNs with the max from the other column \n",
    "    # Then, drop duplicates\n",
    "    group_cols = ['GEOID', 'TOC_Tier', 'zone_class']\n",
    "    df2 = df2.assign(\n",
    "        num_TOC = df2.num_TOC.fillna(df2.groupby(group_cols)['num_TOC'].transform('max')),\n",
    "        num_nonTOC = df2.num_nonTOC.fillna(df2.groupby(group_cols)['num_nonTOC'].transform('max'))\n",
    "    )\n",
    "    \n",
    "    df3 = df2.drop_duplicates(subset = ['GEOID', 'TOC_Tier', 'zone_class', 'num_TOC', 'num_nonTOC'])\n",
    "\n",
    "    df3 = (df3.assign(\n",
    "            num_TOC = df3.num_TOC.fillna(0).astype(int),\n",
    "            num_nonTOC = df3.num_nonTOC.fillna(0).astype(int)\n",
    "        ).drop(columns = ['is_TOC', 'num_cases'])\n",
    "    )    \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyarrow/compat.py:25: FutureWarning: pyarrow.compat has been deprecated and will be removed in a future release\n",
      "  \"future release\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df1 = subset_pcts()   \n",
    "df2 = more_pcts_processing(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_parcels_with_entitlements = make_parcel_level_df(df2)\n",
    "\n",
    "toc_parcels_with_entitlements.to_file(driver = 'GeoJSON', \n",
    "           filename = '../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')\n",
    "\n",
    "s3.upload_file('../gis/intermediate/toc_eligible_parcels_with_entitlements.geojson', \n",
    "               bucket_name, \n",
    "               'gis/intermediate/toc_eligible_parcels_with_entitlements.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parcels applied for each CASE_ID\n",
      "1    1328\n",
      "2     382\n",
      "3     162\n",
      "4     104\n",
      "6      84\n",
      "5      60\n",
      "8      24\n",
      "9       9\n",
      "7       7\n",
      "Name: max_obs, dtype: int64\n",
      "# tiers applied for each CASE_ID\n",
      "1    1559\n",
      "2      88\n",
      "3       9\n",
      "Name: max_obs, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>TOC_Tier</th>\n",
       "      <th>zone_class</th>\n",
       "      <th>num_TOC</th>\n",
       "      <th>num_nonTOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06037104404</td>\n",
       "      <td>0</td>\n",
       "      <td>C2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06037104404</td>\n",
       "      <td>1</td>\n",
       "      <td>C2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06037113212</td>\n",
       "      <td>1</td>\n",
       "      <td>C2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06037113234</td>\n",
       "      <td>1</td>\n",
       "      <td>C2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06037113237</td>\n",
       "      <td>1</td>\n",
       "      <td>C2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GEOID  TOC_Tier zone_class  num_TOC  num_nonTOC\n",
       "0  06037104404         0         C2        0           1\n",
       "1  06037104404         1         C2        0           1\n",
       "2  06037113212         1         C2        0           1\n",
       "3  06037113234         1         C2        0           1\n",
       "4  06037113237         1         C2        0           2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = unique_to_tract_tier_zone(df2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary stats\n",
    "Redo this section to be at case-tract-tier level, not at case-parcel level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parcels: 1912\n",
      "# parcels with TOC entitlements: 472\n",
      "# parcels with non TOC entitlements: 1467\n",
      "# parcels with both TOC and non TOC entitlements: 27\n",
      "double check sum: 1912\n"
     ]
    }
   ],
   "source": [
    "toc_parcels = toc_parcels_with_entitlements[toc_parcels_with_entitlements.num_TOC > 0]\n",
    "non_toc_parcels = toc_parcels_with_entitlements[toc_parcels_with_entitlements.num_nonTOC > 0]\n",
    "have_both_parcels = toc_parcels_with_entitlements[(toc_parcels_with_entitlements.num_TOC > 0) & \n",
    "                                                  (toc_parcels_with_entitlements.num_nonTOC > 0)]\n",
    "\n",
    "print(f'# parcels: {len(toc_parcels_with_entitlements)}')\n",
    "print(f'# parcels with TOC entitlements: {len(toc_parcels)}')\n",
    "print(f'# parcels with non TOC entitlements: {len(non_toc_parcels)}')\n",
    "print(f'# parcels with both TOC and non TOC entitlements: {len(have_both_parcels)}')\n",
    "print(f'double check sum: {len(toc_parcels) + len(non_toc_parcels) - len(have_both_parcels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% parcels with TOC entitlements: 0.5462962962962963\n",
      "% parcels with non TOC entitlements: 1.6979166666666667\n",
      "% parcels with both entitlements: 0.03125\n"
     ]
    }
   ],
   "source": [
    "print(f'% parcels with TOC entitlements: {len(toc_parcels) / len(df)}')\n",
    "print(f'% parcels with non TOC entitlements: {len(non_toc_parcels) / len(df)}')\n",
    "print(f'% parcels with both entitlements: {len(have_both_parcels) / len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       182\n",
       "R3       169\n",
       "R4        82\n",
       "C4        26\n",
       "RD1.5      7\n",
       "R5         3\n",
       "RAS4       2\n",
       "RD2        1\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2       628\n",
       "C4       221\n",
       "R3       145\n",
       "RD1.5    117\n",
       "R2       108\n",
       "RD2       83\n",
       "R4        71\n",
       "C5        28\n",
       "R5        25\n",
       "C1        15\n",
       "RD3       13\n",
       "RAS4      10\n",
       "RD5        1\n",
       "RAS3       1\n",
       "RD4        1\n",
       "Name: zone_class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_toc_parcels.zone_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by TOC Tiers\n",
    "Observations are at the case-tract-tier level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOC_Tier</th>\n",
       "      <th>num_TOC_eligible_tracts</th>\n",
       "      <th>num_TOC</th>\n",
       "      <th>num_nonTOC</th>\n",
       "      <th>pct_TOC</th>\n",
       "      <th>pct_nonTOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>51</td>\n",
       "      <td>350</td>\n",
       "      <td>0.127182</td>\n",
       "      <td>0.872818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>58</td>\n",
       "      <td>239</td>\n",
       "      <td>0.195286</td>\n",
       "      <td>0.804714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>248</td>\n",
       "      <td>177</td>\n",
       "      <td>611</td>\n",
       "      <td>0.224619</td>\n",
       "      <td>0.775381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>132</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOC_Tier  num_TOC_eligible_tracts  num_TOC  num_nonTOC   pct_TOC  \\\n",
       "0         0                       14        3          15  0.166667   \n",
       "1         1                      160       51         350  0.127182   \n",
       "2         2                      144       58         239  0.195286   \n",
       "3         3                      248      177         611  0.224619   \n",
       "4         4                       45       20         132  0.131579   \n",
       "\n",
       "   pct_nonTOC  \n",
       "0    0.833333  \n",
       "1    0.872818  \n",
       "2    0.804714  \n",
       "3    0.775381  \n",
       "4    0.868421  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_by_tiers(df):\n",
    "    df2 = (df.groupby(['TOC_Tier'])\n",
    "           .agg({'GEOID': 'nunique', \n",
    "                 'num_TOC':'sum', \n",
    "                 'num_nonTOC':'sum'})\n",
    "           .rename(columns = {'GEOID': 'num_TOC_eligible_tracts'})\n",
    "           .reset_index()\n",
    "          )\n",
    "    \n",
    "    for i in ['TOC', 'nonTOC']:\n",
    "        new_col = f'pct_{i}'\n",
    "        numerator = f'num_{i}'\n",
    "        df2[new_col] = df2[numerator] / (df2.num_TOC + df2.num_nonTOC)\n",
    "        \n",
    "    return df2\n",
    "\n",
    "by_tiers = summarize_by_tiers(df)\n",
    "by_tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by Zone Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_class</th>\n",
       "      <th>num_TOC_eligible_tracts</th>\n",
       "      <th>num_TOC</th>\n",
       "      <th>num_nonTOC</th>\n",
       "      <th>pct_TOC</th>\n",
       "      <th>pct_nonTOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2</td>\n",
       "      <td>266</td>\n",
       "      <td>107</td>\n",
       "      <td>531</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>0.832288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4</td>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>223</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.929167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R3</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>126</td>\n",
       "      <td>0.489879</td>\n",
       "      <td>0.510121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R4</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAS3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAS4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1.5</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.948529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD2</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RD4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RD5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_class  num_TOC_eligible_tracts  num_TOC  num_nonTOC   pct_TOC  \\\n",
       "0          C1                       10        0          14  0.000000   \n",
       "1          C2                      266      107         531  0.167712   \n",
       "2          C4                       83       17         223  0.070833   \n",
       "3          C5                        2        0          33  0.000000   \n",
       "4          R2                       34        0         109  0.000000   \n",
       "5          R3                      124      121         126  0.489879   \n",
       "6          R4                       59       52          54  0.490566   \n",
       "7          R5                        9        3          22  0.120000   \n",
       "8        RAS3                        1        0           1  0.000000   \n",
       "9        RAS4                        7        1           7  0.125000   \n",
       "10      RD1.5                       59        7         129  0.051471   \n",
       "11        RD2                       48        1          85  0.011628   \n",
       "12        RD3                        6        0          10  0.000000   \n",
       "13        RD4                        1        0           1  0.000000   \n",
       "14        RD5                        1        0           2  0.000000   \n",
       "\n",
       "    pct_nonTOC  \n",
       "0     1.000000  \n",
       "1     0.832288  \n",
       "2     0.929167  \n",
       "3     1.000000  \n",
       "4     1.000000  \n",
       "5     0.510121  \n",
       "6     0.509434  \n",
       "7     0.880000  \n",
       "8     1.000000  \n",
       "9     0.875000  \n",
       "10    0.948529  \n",
       "11    0.988372  \n",
       "12    1.000000  \n",
       "13    1.000000  \n",
       "14    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_by_zones(df):\n",
    "    df2 = (df.groupby('zone_class')\n",
    "           .agg({'GEOID':'nunique', \n",
    "                 'num_TOC':'sum', \n",
    "                 'num_nonTOC':'sum'})\n",
    "           .rename(columns = {'GEOID': 'num_TOC_eligible_tracts'})\n",
    "           .reset_index()\n",
    "          )\n",
    "    \n",
    "    for i in ['TOC', 'nonTOC']:\n",
    "        new_col = f'pct_{i}'\n",
    "        numerator = f'num_{i}'\n",
    "        df2[new_col] = df2[numerator] / (df2.num_TOC + df2.num_nonTOC)\n",
    "        \n",
    "    return df2\n",
    "\n",
    "by_zones = summarize_by_zones(df)\n",
    "by_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../outputs/toc_charts.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "by_tiers.to_excel(writer, sheet_name = 'entitlements_by_tier')\n",
    "by_zones.to_excel(writer, sheet_name = 'entitlements_by_zone')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
