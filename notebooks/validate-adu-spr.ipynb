{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check original file against published reports\n",
    "## ADU / SPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import laplan\n",
    "\n",
    "catalog = intake.open_catalog('../catalogs/*.yml')\n",
    "bucket_name = \"city-planning-entitlements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"1/1/10\"\n",
    "end_date = \"10/31/19\"\n",
    "\n",
    "# Let's throw our new master_pcts into the d1_step_by_step\n",
    "#master_pcts = catalog.pcts2.read()\n",
    "master_pcts = pd.read_parquet('s3://city-planning-entitlements/test_new_master_pcts.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCTS Reporting Module Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_subset(name):\n",
    "    df = pd.read_excel(f'../data/pcts_{name}.xlsx', skiprows=4)\n",
    "    keep = [\"CASE NUMBER\", \"FILE DATE\"]\n",
    "    df = df[keep].rename(columns = {\"CASE NUMBER\": \"CASE_NBR\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA laplan function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All prefixes and suffixes\n",
    "# This is our old master_pcts\n",
    "def laplan_subset(name):\n",
    "    name = name.upper()\n",
    "    pcts = laplan.pcts.subset_pcts(\n",
    "        master_pcts, \n",
    "        start_date = start_date , end_date = end_date,\n",
    "        get_dummies=True, verbose=False)\n",
    "    pcts = laplan.pcts.drop_child_cases(pcts, keep_child_entitlements=False)\n",
    "    \n",
    "    pcts = pcts[pcts[name]==True]\n",
    "    \n",
    "    return pcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA step-by-step in creating master_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ita_step_by_step(name):\n",
    "    name = name.upper()\n",
    "    print(f\"{name}: Creating master PCTS step-by-step\")\n",
    "    \n",
    "    case = pd.read_parquet(f's3://{bucket_name}/data/raw/tCASE.parquet')\n",
    "    app = pd.read_parquet(f's3://{bucket_name}/data/raw/tAPLC.parquet')\n",
    "    geo_info = pd.read_parquet(f's3://{bucket_name}/data/raw/tPROP_GEO_INFO.parquet')\n",
    "    la_prop = pd.read_parquet(f's3://{bucket_name}/data/raw/tLA_PROP.parquet')\n",
    "\n",
    "    app1 = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "    geo_info1 = geo_info[['CASE_ID', 'PROP_ID']]\n",
    "    la_prop1 = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]\n",
    "    \n",
    "    # Subset by start/end date\n",
    "    case2 = case[(case.CASE_FILE_RCV_DT >= start_date) & \n",
    "            (case.CASE_FILE_RCV_DT <= end_date)]\n",
    "    \n",
    "    # Subset by suffix \n",
    "    case3 = case2[case2.CASE_NBR.str.contains(f\"-{name}\")]\n",
    "    \n",
    "    print(f'1-# unique cases (parents + child): {case3.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Keep parent cases only\n",
    "    case4 = case3[case3.PARNT_CASE_ID.isna()]\n",
    "    \n",
    "    print(f'2-# unique cases (parents): {case4.CASE_NBR.nunique()}')\n",
    "    \n",
    "    m1 = pd.merge(case4, geo_info1, on = 'CASE_ID', how = 'inner', validate = '1:m')\n",
    "    m2 = pd.merge(m1, la_prop1, on = 'PROP_ID', how = 'inner', validate = 'm:1')\n",
    "    m3 = pd.merge(m2, app1, on = 'APLC_ID', how = 'left', validate = 'm:1')\n",
    "    \n",
    "    print(f'3-# unique cases (parents), with geo_info merged: {m1.CASE_NBR.nunique()}')\n",
    "    print(f'4-# unique cases (parents), with la_prop merged: {m2.CASE_NBR.nunique()}')\n",
    "    print(f'5-# unique cases (parents), with app merged: {m3.CASE_NBR.nunique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA D1 step-by-step for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_list = laplan.pcts.VALID_PCTS_PREFIX\n",
    "suffix_list = laplan.pcts.VALID_PCTS_SUFFIX\n",
    "\n",
    "remove_prefix = [\"ENV\"]\n",
    "remove_suffix = [\n",
    "    \"EIR\",\n",
    "    \"IPRO\",\n",
    "    \"CA\",\n",
    "    \"CATEX\",\n",
    "    \"CPIO\",\n",
    "    \"CPU\",\n",
    "    \"FH\",\n",
    "    \"G\",\n",
    "    \"HD\",\n",
    "    \"HPOZ\",\n",
    "    \"ICO\",\n",
    "    \"K\",\n",
    "    \"LCP\",\n",
    "    \"NSO\",\n",
    "    \"S\",\n",
    "    \"SN\",\n",
    "    \"SP\",\n",
    "    \"ZAI\",\n",
    "    \"CRA\", \n",
    "    \"RFA\",\n",
    "]\n",
    "\n",
    "prefix_list = [x for x in prefix_list if x not in remove_prefix]\n",
    "suffix_list = [x for x in suffix_list if x not in remove_suffix]\n",
    "\n",
    "def d1_step_by_step(name):\n",
    "    name = name.upper()\n",
    "    print(f\"{name}: D1 step-by-step\")\n",
    "        \n",
    "    # Load PCTS and subset to the prefix / suffix list we want\n",
    "    pcts = laplan.pcts.subset_pcts(\n",
    "        master_pcts,\n",
    "        start_date = start_date, end_date = end_date,\n",
    "        prefix_list=prefix_list, suffix_list=suffix_list,\n",
    "        get_dummies=True, verbose=False,\n",
    "    )\n",
    "    pcts = laplan.pcts.drop_child_cases(pcts, keep_child_entitlements=True)\n",
    "    pcts = pcts[pcts[name]==True][[\"CASE_NBR\", \"CASE_ID\", \"AIN\"]]\n",
    "    \n",
    "    print(f'1-# unique cases (parents) using laplan: {pcts.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Add on tract info\n",
    "    # See which cases have AINs, but those AINs are not mapped onto tract GEOID\n",
    "    parcel_to_tract = catalog.crosswalk_parcels_tracts.read()\n",
    "    parcel_to_tract = parcel_to_tract[[\"AIN\", \"num_AIN\", \"GEOID\"]]\n",
    "\n",
    "    pcts = pd.merge(\n",
    "        pcts,\n",
    "        parcel_to_tract, \n",
    "        on=\"AIN\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:1\",\n",
    "    )\n",
    "    \n",
    "    print(f'2-# unique cases (parents), with tract merged in: {pcts.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Clean AIN data and get rid of outliers\n",
    "    case_counts = pcts.CASE_ID.value_counts()\n",
    "    big_cases = pcts[pcts.CASE_ID.isin(case_counts[case_counts > 20].index)]\n",
    "\n",
    "    pcts = pcts[~pcts.CASE_ID.isin(big_cases.CASE_ID)]\n",
    "    \n",
    "    print(f'3-# unique cases (parents) removing outliers: {pcts.CASE_NBR.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put functions all together\n",
    "def comparison(suffix):\n",
    "    dcp = import_and_subset(suffix)\n",
    "    ita = laplan_subset(suffix)\n",
    "\n",
    "    print(\"Discrepancies in DCP vs ITA\")\n",
    "    print(f'DCP-{suffix.upper()} unique cases (parents) in PCTS report: {dcp.CASE_NBR.nunique()}')\n",
    "    print(f'ITA-{suffix.upper()} unique cases (parents) with laplan, all prefixes/suffixes: {ita.CASE_NBR.nunique()}')    \n",
    "    #ita_step_by_step(suffix)\n",
    "    d1_step_by_step(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in DCP vs ITA\n",
      "DCP-1A unique cases (parents) in PCTS report: 1412\n",
      "ITA-1A unique cases (parents) with laplan, all prefixes/suffixes: 0\n",
      "1A: D1 step-by-step\n",
      "1-# unique cases (parents) using laplan: 1110\n",
      "2-# unique cases (parents), with tract merged in: 1110\n",
      "3-# unique cases (parents) removing outliers: 1110\n"
     ]
    }
   ],
   "source": [
    "comparison(\"1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in DCP vs ITA\n",
      "DCP-2A unique cases (parents) in PCTS report: 119\n",
      "ITA-2A unique cases (parents) with laplan, all prefixes/suffixes: 0\n",
      "2A: D1 step-by-step\n",
      "1-# unique cases (parents) using laplan: 67\n",
      "2-# unique cases (parents), with tract merged in: 67\n",
      "3-# unique cases (parents) removing outliers: 67\n"
     ]
    }
   ],
   "source": [
    "comparison(\"2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in DCP vs ITA\n",
      "DCP-5A unique cases (parents) in PCTS report: 3\n",
      "ITA-5A unique cases (parents) with laplan, all prefixes/suffixes: 0\n",
      "5A: D1 step-by-step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'5A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '5A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8f3a9086e0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-b5d38f16cfcd>\u001b[0m in \u001b[0;36mcomparison\u001b[0;34m(suffix)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ITA-{suffix.upper()} unique cases (parents) with laplan, all prefixes/suffixes: {ita.CASE_NBR.nunique()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#ita_step_by_step(suffix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0md1_step_by_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-30908115ac8d>\u001b[0m in \u001b[0;36md1_step_by_step\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[0mpcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_child_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_child_entitlements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mpcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpcts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CASE_NBR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CASE_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AIN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'1-# unique cases (parents) using laplan: {pcts.CASE_NBR.nunique()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '5A'"
     ]
    }
   ],
   "source": [
    "comparison(\"5a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison(\"adu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison(\"spr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
