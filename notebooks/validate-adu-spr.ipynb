{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check original file against published reports\n",
    "## ADU / SPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import laplan\n",
    "\n",
    "catalog = intake.open_catalog('../catalogs/*.yml')\n",
    "bucket_name = \"city-planning-entitlements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"1/1/10\"\n",
    "end_date = \"10/31/19\"\n",
    "\n",
    "master_pcts = catalog.pcts2.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCTS Reporting Module Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_subset(name):\n",
    "    df = pd.read_excel(f'../data/pcts_{name}.xlsx', skiprows=4)\n",
    "    keep = [\"CASE NUMBER\", \"FILE DATE\"]\n",
    "    df = df[keep].rename(columns = {\"CASE NUMBER\": \"CASE_NBR\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA laplan function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All prefixes and suffixes\n",
    "def laplan_subset(name):\n",
    "    name = name.upper()\n",
    "    pcts = laplan.pcts.subset_pcts(\n",
    "        master_pcts, \n",
    "        start_date = start_date , end_date = end_date,\n",
    "        get_dummies=True, verbose=False)\n",
    "    pcts = laplan.pcts.drop_child_cases(pcts, keep_child_entitlements=False)\n",
    "    \n",
    "    pcts = pcts[pcts[name]==True]\n",
    "    \n",
    "    return pcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA step-by-step in creating master_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ita_step_by_step(name):\n",
    "    name = name.upper()\n",
    "    print(f\"{name}: Creating master PCTS step-by-step\")\n",
    "    \n",
    "    case = pd.read_parquet(f's3://{bucket_name}/data/raw/tCASE.parquet')\n",
    "    app = pd.read_parquet(f's3://{bucket_name}/data/raw/tAPLC.parquet')\n",
    "    geo_info = pd.read_parquet(f's3://{bucket_name}/data/raw/tPROP_GEO_INFO.parquet')\n",
    "    la_prop = pd.read_parquet(f's3://{bucket_name}/data/raw/tLA_PROP.parquet')\n",
    "\n",
    "    app1 = app[['APLC_ID', 'PROJ_DESC_TXT']]\n",
    "    geo_info1 = geo_info[['CASE_ID', 'PROP_ID']]\n",
    "    la_prop1 = la_prop[la_prop.ASSR_PRCL_NBR.notna()][['PROP_ID', 'ASSR_PRCL_NBR']]\n",
    "    \n",
    "    # Subset by start/end date\n",
    "    case2 = case[(case.CASE_FILE_RCV_DT >= start_date) & \n",
    "            (case.CASE_FILE_RCV_DT <= end_date)]\n",
    "    \n",
    "    # Subset by suffix \n",
    "    case3 = case2[case2.CASE_NBR.str.contains(f\"-{name}\")]\n",
    "    \n",
    "    print(f'1-# unique cases (parents + child): {case3.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Keep parent cases only\n",
    "    case4 = case3[case3.PARNT_CASE_ID.isna()]\n",
    "    \n",
    "    print(f'2-# unique cases (parents): {case4.CASE_NBR.nunique()}')\n",
    "    \n",
    "    m1 = pd.merge(case4, geo_info1, on = 'CASE_ID', how = 'inner', validate = '1:m')\n",
    "    m2 = pd.merge(m1, la_prop1, on = 'PROP_ID', how = 'inner', validate = 'm:1')\n",
    "    m3 = pd.merge(m2, app1, on = 'APLC_ID', how = 'left', validate = 'm:1')\n",
    "    \n",
    "    print(f'3-# unique cases (parents), with geo_info merged: {m1.CASE_NBR.nunique()}')\n",
    "    print(f'4-# unique cases (parents), with la_prop merged: {m2.CASE_NBR.nunique()}')\n",
    "    print(f'5-# unique cases (parents), with app merged: {m3.CASE_NBR.nunique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA D1 step-by-step for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_list = laplan.pcts.VALID_PCTS_PREFIX\n",
    "suffix_list = laplan.pcts.VALID_PCTS_SUFFIX\n",
    "\n",
    "remove_prefix = [\"ENV\"]\n",
    "remove_suffix = [\n",
    "    \"EIR\",\n",
    "    \"IPRO\",\n",
    "    \"CA\",\n",
    "    \"CATEX\",\n",
    "    \"CPIO\",\n",
    "    \"CPU\",\n",
    "    \"FH\",\n",
    "    \"G\",\n",
    "    \"HD\",\n",
    "    \"HPOZ\",\n",
    "    \"ICO\",\n",
    "    \"K\",\n",
    "    \"LCP\",\n",
    "    \"NSO\",\n",
    "    \"S\",\n",
    "    \"SN\",\n",
    "    \"SP\",\n",
    "    \"ZAI\",\n",
    "    \"CRA\", \n",
    "    \"RFA\",\n",
    "]\n",
    "\n",
    "prefix_list = [x for x in prefix_list if x not in remove_prefix]\n",
    "suffix_list = [x for x in suffix_list if x not in remove_suffix]\n",
    "\n",
    "def d1_step_by_step(name):\n",
    "    name = name.upper()\n",
    "    print(f\"{name}: D1 step-by-step\")\n",
    "        \n",
    "    # Load PCTS and subset to the prefix / suffix list we want\n",
    "    pcts = laplan.pcts.subset_pcts(\n",
    "        master_pcts,\n",
    "        start_date = start_date, end_date = end_date,\n",
    "        prefix_list=prefix_list, suffix_list=suffix_list,\n",
    "        get_dummies=True, verbose=False,\n",
    "    )\n",
    "    pcts = laplan.pcts.drop_child_cases(pcts, keep_child_entitlements=True)\n",
    "    pcts = pcts[pcts[name]==True][[\"CASE_NBR\", \"CASE_ID\", \"AIN\"]]\n",
    "    \n",
    "    print(f'1-# unique cases (parents) using laplan: {pcts.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Add on tract info\n",
    "    # See which cases have AINs, but those AINs are not mapped onto tract GEOID\n",
    "    parcel_to_tract = catalog.crosswalk_parcels_tracts.read()\n",
    "    parcel_to_tract = parcel_to_tract[[\"AIN\", \"num_AIN\", \"GEOID\"]]\n",
    "\n",
    "    pcts = pd.merge(\n",
    "        pcts,\n",
    "        parcel_to_tract, \n",
    "        on=\"AIN\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:1\",\n",
    "    )\n",
    "    \n",
    "    print(f'2-# unique cases (parents), with tract merged in: {pcts.CASE_NBR.nunique()}')\n",
    "    \n",
    "    # Clean AIN data and get rid of outliers\n",
    "    case_counts = pcts.CASE_ID.value_counts()\n",
    "    big_cases = pcts[pcts.CASE_ID.isin(case_counts[case_counts > 20].index)]\n",
    "\n",
    "    pcts = pcts[~pcts.CASE_ID.isin(big_cases.CASE_ID)]\n",
    "    \n",
    "    print(f'3-# unique cases (parents) removing outliers: {pcts.CASE_NBR.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put functions all together\n",
    "def comparison(suffix):\n",
    "    dcp = import_and_subset(suffix)\n",
    "    ita = laplan_subset(suffix)\n",
    "\n",
    "    print(\"Discrepancies in DCP vs ITA\")\n",
    "    print(f'DCP-{suffix.upper()} unique cases (parents) in PCTS report: {dcp.CASE_NBR.nunique()}')\n",
    "    print(f'ITA-{suffix.upper()} unique cases (parents) with laplan, all prefixes/suffixes: {ita.CASE_NBR.nunique()}')    \n",
    "    ita_step_by_step(suffix)\n",
    "    d1_step_by_step(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in DCP vs ITA\n",
      "DCP-ADU unique cases (parents) in PCTS report: 438\n",
      "ITA-ADU unique cases (parents) with laplan, all prefixes/suffixes: 438\n",
      "ADU: Creating master PCTS step-by-step\n",
      "1-# unique cases (parents + child): 455\n",
      "2-# unique cases (parents): 455\n",
      "3-# unique cases (parents), with geo_info merged: 438\n",
      "4-# unique cases (parents), with la_prop merged: 438\n",
      "5-# unique cases (parents), with app merged: 438\n",
      "ADU: D1 step-by-step\n",
      "1-# unique cases (parents) using laplan: 438\n",
      "2-# unique cases (parents), with tract merged in: 419\n",
      "3-# unique cases (parents) removing outliers: 419\n"
     ]
    }
   ],
   "source": [
    "comparison(\"adu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in DCP vs ITA\n",
      "DCP-SPR unique cases (parents) in PCTS report: 809\n",
      "ITA-SPR unique cases (parents) with laplan, all prefixes/suffixes: 789\n",
      "SPR: Creating master PCTS step-by-step\n",
      "1-# unique cases (parents + child): 1141\n",
      "2-# unique cases (parents): 817\n",
      "3-# unique cases (parents), with geo_info merged: 794\n",
      "4-# unique cases (parents), with la_prop merged: 789\n",
      "5-# unique cases (parents), with app merged: 789\n",
      "SPR: D1 step-by-step\n",
      "1-# unique cases (parents) using laplan: 651\n",
      "2-# unique cases (parents), with tract merged in: 439\n",
      "3-# unique cases (parents) removing outliers: 438\n"
     ]
    }
   ],
   "source": [
    "comparison(\"spr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
